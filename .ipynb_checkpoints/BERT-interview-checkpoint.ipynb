{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 1.x\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# np.random.seed(1337)\n",
    "from keras import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import LSTM, Dense, Masking\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Dense, Input, concatenate, Layer, Lambda, Dropout, Activation\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, TensorBoard\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'label1-g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unnamed:_0</th>\n",
       "      <th>interview_id</th>\n",
       "      <th>interview_date</th>\n",
       "      <th>record_creation_date</th>\n",
       "      <th>venue</th>\n",
       "      <th>address_name</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state_/_province</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>...</th>\n",
       "      <th>interviewer_relationship_5_to_storyteller_2</th>\n",
       "      <th>language_1</th>\n",
       "      <th>language_2</th>\n",
       "      <th>language_3</th>\n",
       "      <th>keywords_-_fixed_subjects</th>\n",
       "      <th>keywords_-_general</th>\n",
       "      <th>keywords_-_places</th>\n",
       "      <th>deep_speech</th>\n",
       "      <th>human_transcript</th>\n",
       "      <th>google_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MBY005668</td>\n",
       "      <td>9/5/09 11:30</td>\n",
       "      <td>9/5/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Achievements and Awards\\n\\nChildren\\n\\nCommuni...</td>\n",
       "      <td>bilingual\\n\\nBilingue\\n\\nChihuahua, Mexico\\n\\n...</td>\n",
       "      <td></td>\n",
       "      <td>i am an amadis so my lawyer in whitewashin or ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I mean I'm already so my lawyer Singapore and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MBY005704</td>\n",
       "      <td>9/12/09 14:30</td>\n",
       "      <td>9/12/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Childcare\\n\\nChildren\\n\\nTraumatic Memories</td>\n",
       "      <td>accidents\\n\\nbilingual\\n\\nbirth of first child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all me i olliphant elocution cutaneous or a sa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>call mi amor Alejandro De La Cruz Munoz arrest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MBY005712</td>\n",
       "      <td>9/13/09 17:30</td>\n",
       "      <td>9/13/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anniversaries\\n\\nChildren\\n\\nCommunity Busines...</td>\n",
       "      <td>accidents\\n\\nbaile\\n\\ncar accident\\n\\ncemetery...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it kanonsionni neesnetasis officiousness miste...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>okay mean Hombres es el Amante Samira cincuent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MBY005713</td>\n",
       "      <td>9/14/09 9:30</td>\n",
       "      <td>9/14/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Birth\\n\\nBurials\\n\\nCancer\\n\\nChildcare\\n\\nChi...</td>\n",
       "      <td>alcohol\\n\\nbirth of first child\\n\\nchemotherap...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my name is maria humphry i'm twenty six to day...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my name is Melissa Humphrey I'm 26 today's dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MBY005730</td>\n",
       "      <td>9/18/09 12:30</td>\n",
       "      <td>9/18/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Changes In Education\\n\\nCommunity Businesses\\n...</td>\n",
       "      <td>anecdotes (humorous but true stories)\\n\\nappea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the woman silence hello my name is alan fucara...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hello my name is Adolfo Carranza Junior and I'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unnamed:_0 interview_id interview_date record_creation_date  \\\n",
       "0           0    MBY005668   9/5/09 11:30               9/5/09   \n",
       "1           1    MBY005704  9/12/09 14:30              9/12/09   \n",
       "2           2    MBY005712  9/13/09 17:30              9/13/09   \n",
       "3           3    MBY005713   9/14/09 9:30              9/14/09   \n",
       "4           4    MBY005730  9/18/09 12:30              9/18/09   \n",
       "\n",
       "                    venue      address_name                 street    city  \\\n",
       "0  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library  Paonia   \n",
       "1  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library  Paonia   \n",
       "2  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library  Paonia   \n",
       "3  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library  Paonia   \n",
       "4  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library  Paonia   \n",
       "\n",
       "  state_/_province  postal_code  ...  \\\n",
       "0               CO      81428.0  ...   \n",
       "1               CO      81428.0  ...   \n",
       "2               CO      81428.0  ...   \n",
       "3               CO      81428.0  ...   \n",
       "4               CO      81428.0  ...   \n",
       "\n",
       "  interviewer_relationship_5_to_storyteller_2 language_1 language_2  \\\n",
       "0                                         NaN    Spanish        NaN   \n",
       "1                                         NaN    Spanish        NaN   \n",
       "2                                         NaN    Spanish        NaN   \n",
       "3                                         NaN    English        NaN   \n",
       "4                                         NaN        NaN        NaN   \n",
       "\n",
       "  language_3                          keywords_-_fixed_subjects  \\\n",
       "0        NaN  Achievements and Awards\\n\\nChildren\\n\\nCommuni...   \n",
       "1        NaN        Childcare\\n\\nChildren\\n\\nTraumatic Memories   \n",
       "2        NaN  Anniversaries\\n\\nChildren\\n\\nCommunity Busines...   \n",
       "3        NaN  Birth\\n\\nBurials\\n\\nCancer\\n\\nChildcare\\n\\nChi...   \n",
       "4        NaN  Changes In Education\\n\\nCommunity Businesses\\n...   \n",
       "\n",
       "                                  keywords_-_general keywords_-_places  \\\n",
       "0  bilingual\\n\\nBilingue\\n\\nChihuahua, Mexico\\n\\n...                     \n",
       "1  accidents\\n\\nbilingual\\n\\nbirth of first child...               NaN   \n",
       "2  accidents\\n\\nbaile\\n\\ncar accident\\n\\ncemetery...               NaN   \n",
       "3  alcohol\\n\\nbirth of first child\\n\\nchemotherap...               NaN   \n",
       "4  anecdotes (humorous but true stories)\\n\\nappea...               NaN   \n",
       "\n",
       "                                         deep_speech  human_transcript  \\\n",
       "0  i am an amadis so my lawyer in whitewashin or ...               NaN   \n",
       "1  all me i olliphant elocution cutaneous or a sa...               NaN   \n",
       "2  it kanonsionni neesnetasis officiousness miste...               NaN   \n",
       "3  my name is maria humphry i'm twenty six to day...               NaN   \n",
       "4  the woman silence hello my name is alan fucara...               NaN   \n",
       "\n",
       "                                   google_transcript  \n",
       "0  I mean I'm already so my lawyer Singapore and ...  \n",
       "1  call mi amor Alejandro De La Cruz Munoz arrest...  \n",
       "2  okay mean Hombres es el Amante Samira cincuent...  \n",
       "3  my name is Melissa Humphrey I'm 26 today's dat...  \n",
       "4  hello my name is Adolfo Carranza Junior and I'...  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_raw = pd.read_csv('Data/transcript.csv')\n",
    "transcript_raw.columns = transcript_raw.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "transcript_raw = transcript_raw[transcript_raw.google_transcript.notnull()]\n",
    "transcript_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349, 61)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interview_id</th>\n",
       "      <th>interview_date</th>\n",
       "      <th>record_creation_date</th>\n",
       "      <th>venue</th>\n",
       "      <th>address_name</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state_/_province</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>interview_description</th>\n",
       "      <th>...</th>\n",
       "      <th>interviewer_relationship_1_to_storyteller_1</th>\n",
       "      <th>language_1</th>\n",
       "      <th>keywords_-_fixed_subjects</th>\n",
       "      <th>keywords_-_general</th>\n",
       "      <th>label1-fs</th>\n",
       "      <th>label2-fs</th>\n",
       "      <th>label3-fs</th>\n",
       "      <th>label1-g</th>\n",
       "      <th>label2-g</th>\n",
       "      <th>label3-g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MBY005668</td>\n",
       "      <td>2009/9/5 11:30</td>\n",
       "      <td>2009/9/5</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428</td>\n",
       "      <td>Rita Elvia Loya (38) habla con su esposo Omar ...</td>\n",
       "      <td>...</td>\n",
       "      <td>wife</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Achievements and Awards\\n\\nChildren\\n\\nCommuni...</td>\n",
       "      <td>bilingual\\n\\nBilingue\\n\\nChihuahua, Mexico\\n\\n...</td>\n",
       "      <td>Children</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>Immigration Stories</td>\n",
       "      <td>social beliefs and practices</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>memories of former times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MBY005712</td>\n",
       "      <td>2009/9/13 17:30</td>\n",
       "      <td>2009/9/13</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428</td>\n",
       "      <td>Cecilio Montes (46) habla con esposa Bertha Ja...</td>\n",
       "      <td>...</td>\n",
       "      <td>esposa</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Anniversaries\\n\\nChildren\\n\\nCommunity Busines...</td>\n",
       "      <td>accidents\\n\\nbaile\\n\\ncar accident\\n\\ncemetery...</td>\n",
       "      <td>Children</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>Immigration Stories</td>\n",
       "      <td>memories of former times</td>\n",
       "      <td>spouse</td>\n",
       "      <td>family tradition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MBY005713</td>\n",
       "      <td>2009/9/14 9:30</td>\n",
       "      <td>2009/9/14</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428</td>\n",
       "      <td>Alice talks about childhood.  Melissa remember...</td>\n",
       "      <td>...</td>\n",
       "      <td>grandmother</td>\n",
       "      <td>English</td>\n",
       "      <td>Birth\\n\\nBurials\\n\\nCancer\\n\\nChildcare\\n\\nChi...</td>\n",
       "      <td>alcohol\\n\\nbirth of first child\\n\\nchemotherap...</td>\n",
       "      <td>Parents</td>\n",
       "      <td>Children</td>\n",
       "      <td>Marriage</td>\n",
       "      <td>memories of growing up</td>\n",
       "      <td>memories of former times</td>\n",
       "      <td>family tradition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MBY005730</td>\n",
       "      <td>2009/9/18 12:30</td>\n",
       "      <td>2009/9/18</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428</td>\n",
       "      <td>Adolph Carranza Jr. (64) talks with friend Ele...</td>\n",
       "      <td>...</td>\n",
       "      <td>friend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Changes In Education\\n\\nCommunity Businesses\\n...</td>\n",
       "      <td>anecdotes (humorous but true stories)\\n\\nappea...</td>\n",
       "      <td>Parents</td>\n",
       "      <td>Schools</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>memories of growing up</td>\n",
       "      <td>social beliefs and practices</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MBY005764</td>\n",
       "      <td>2009/9/28 10:30</td>\n",
       "      <td>2009/9/28</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Public Library</td>\n",
       "      <td>Colorado Springs</td>\n",
       "      <td>CO</td>\n",
       "      <td>80911</td>\n",
       "      <td>Rosana interviews her friend Alberta about her...</td>\n",
       "      <td>...</td>\n",
       "      <td>friend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Education\\n\\nAchievements and Awards\\n\\nArmy\\n...</td>\n",
       "      <td>advocacy\\n\\nadvocate\\n\\ncollege\\n\\ndevelopment...</td>\n",
       "      <td>Schools</td>\n",
       "      <td>Children</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>memories of former times</td>\n",
       "      <td>school day memories</td>\n",
       "      <td>spouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  interview_id   interview_date record_creation_date                   venue  \\\n",
       "0    MBY005668   2009/9/5 11:30             2009/9/5  MobileBooth West (MBY)   \n",
       "1    MBY005712  2009/9/13 17:30            2009/9/13  MobileBooth West (MBY)   \n",
       "2    MBY005713   2009/9/14 9:30            2009/9/14  MobileBooth West (MBY)   \n",
       "3    MBY005730  2009/9/18 12:30            2009/9/18  MobileBooth West (MBY)   \n",
       "4    MBY005764  2009/9/28 10:30            2009/9/28  MobileBooth West (MBY)   \n",
       "\n",
       "       address_name                 street              city state_/_province  \\\n",
       "0  MobileBooth West  Paonia Public Library            Paonia               CO   \n",
       "1  MobileBooth West  Paonia Public Library            Paonia               CO   \n",
       "2  MobileBooth West  Paonia Public Library            Paonia               CO   \n",
       "3  MobileBooth West  Paonia Public Library            Paonia               CO   \n",
       "4  MobileBooth West         Public Library  Colorado Springs               CO   \n",
       "\n",
       "   postal_code                              interview_description  ...  \\\n",
       "0        81428  Rita Elvia Loya (38) habla con su esposo Omar ...  ...   \n",
       "1        81428  Cecilio Montes (46) habla con esposa Bertha Ja...  ...   \n",
       "2        81428  Alice talks about childhood.  Melissa remember...  ...   \n",
       "3        81428  Adolph Carranza Jr. (64) talks with friend Ele...  ...   \n",
       "4        80911  Rosana interviews her friend Alberta about her...  ...   \n",
       "\n",
       "  interviewer_relationship_1_to_storyteller_1 language_1  \\\n",
       "0                                        wife    Spanish   \n",
       "1                                      esposa    Spanish   \n",
       "2                                 grandmother    English   \n",
       "3                                      friend        NaN   \n",
       "4                                      friend        NaN   \n",
       "\n",
       "                           keywords_-_fixed_subjects  \\\n",
       "0  Achievements and Awards\\n\\nChildren\\n\\nCommuni...   \n",
       "1  Anniversaries\\n\\nChildren\\n\\nCommunity Busines...   \n",
       "2  Birth\\n\\nBurials\\n\\nCancer\\n\\nChildcare\\n\\nChi...   \n",
       "3  Changes In Education\\n\\nCommunity Businesses\\n...   \n",
       "4  Education\\n\\nAchievements and Awards\\n\\nArmy\\n...   \n",
       "\n",
       "                                  keywords_-_general label1-fs     label2-fs  \\\n",
       "0  bilingual\\n\\nBilingue\\n\\nChihuahua, Mexico\\n\\n...  Children  Workday Life   \n",
       "1  accidents\\n\\nbaile\\n\\ncar accident\\n\\ncemetery...  Children  Workday Life   \n",
       "2  alcohol\\n\\nbirth of first child\\n\\nchemotherap...   Parents      Children   \n",
       "3  anecdotes (humorous but true stories)\\n\\nappea...   Parents       Schools   \n",
       "4  advocacy\\n\\nadvocate\\n\\ncollege\\n\\ndevelopment...   Schools      Children   \n",
       "\n",
       "             label3-fs                      label1-g  \\\n",
       "0  Immigration Stories  social beliefs and practices   \n",
       "1  Immigration Stories      memories of former times   \n",
       "2             Marriage        memories of growing up   \n",
       "3         Workday Life        memories of growing up   \n",
       "4         Workday Life      memories of former times   \n",
       "\n",
       "                       label2-g                  label3-g  \n",
       "0                     ethnicity  memories of former times  \n",
       "1                        spouse          family tradition  \n",
       "2      memories of former times          family tradition  \n",
       "3  social beliefs and practices                 ethnicity  \n",
       "4           school day memories                    spouse  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_raw = pd.read_csv('Data/labels.csv')\n",
    "label_raw.columns = label_raw.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "label_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unnamed:_0</th>\n",
       "      <th>interview_id</th>\n",
       "      <th>interview_date_x</th>\n",
       "      <th>record_creation_date_x</th>\n",
       "      <th>venue_x</th>\n",
       "      <th>address_name_x</th>\n",
       "      <th>street_x</th>\n",
       "      <th>city_x</th>\n",
       "      <th>state_/_province_x</th>\n",
       "      <th>postal_code_x</th>\n",
       "      <th>...</th>\n",
       "      <th>interviewer_relationship_1_to_storyteller_1_y</th>\n",
       "      <th>language_1_y</th>\n",
       "      <th>keywords_-_fixed_subjects_y</th>\n",
       "      <th>keywords_-_general_y</th>\n",
       "      <th>label1-fs</th>\n",
       "      <th>label2-fs</th>\n",
       "      <th>label3-fs</th>\n",
       "      <th>label1-g</th>\n",
       "      <th>label2-g</th>\n",
       "      <th>label3-g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MBY005668</td>\n",
       "      <td>9/5/09 11:30</td>\n",
       "      <td>9/5/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>wife</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Achievements and Awards\\n\\nChildren\\n\\nCommuni...</td>\n",
       "      <td>bilingual\\n\\nBilingue\\n\\nChihuahua, Mexico\\n\\n...</td>\n",
       "      <td>Children</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>Immigration Stories</td>\n",
       "      <td>social beliefs and practices</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>memories of former times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MBY005712</td>\n",
       "      <td>9/13/09 17:30</td>\n",
       "      <td>9/13/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>esposa</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Anniversaries\\n\\nChildren\\n\\nCommunity Busines...</td>\n",
       "      <td>accidents\\n\\nbaile\\n\\ncar accident\\n\\ncemetery...</td>\n",
       "      <td>Children</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>Immigration Stories</td>\n",
       "      <td>memories of former times</td>\n",
       "      <td>spouse</td>\n",
       "      <td>family tradition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MBY005713</td>\n",
       "      <td>9/14/09 9:30</td>\n",
       "      <td>9/14/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>grandmother</td>\n",
       "      <td>English</td>\n",
       "      <td>Birth\\n\\nBurials\\n\\nCancer\\n\\nChildcare\\n\\nChi...</td>\n",
       "      <td>alcohol\\n\\nbirth of first child\\n\\nchemotherap...</td>\n",
       "      <td>Parents</td>\n",
       "      <td>Children</td>\n",
       "      <td>Marriage</td>\n",
       "      <td>memories of growing up</td>\n",
       "      <td>memories of former times</td>\n",
       "      <td>family tradition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MBY005730</td>\n",
       "      <td>9/18/09 12:30</td>\n",
       "      <td>9/18/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>friend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Changes In Education\\n\\nCommunity Businesses\\n...</td>\n",
       "      <td>anecdotes (humorous but true stories)\\n\\nappea...</td>\n",
       "      <td>Parents</td>\n",
       "      <td>Schools</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>memories of growing up</td>\n",
       "      <td>social beliefs and practices</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>MBY005764</td>\n",
       "      <td>9/28/09 10:30</td>\n",
       "      <td>9/28/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Public Library</td>\n",
       "      <td>Colorado Springs</td>\n",
       "      <td>CO</td>\n",
       "      <td>80911.0</td>\n",
       "      <td>...</td>\n",
       "      <td>friend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Education\\n\\nAchievements and Awards\\n\\nArmy\\n...</td>\n",
       "      <td>advocacy\\n\\nadvocate\\n\\ncollege\\n\\ndevelopment...</td>\n",
       "      <td>Schools</td>\n",
       "      <td>Children</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>memories of former times</td>\n",
       "      <td>school day memories</td>\n",
       "      <td>spouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unnamed:_0 interview_id interview_date_x record_creation_date_x  \\\n",
       "0           0    MBY005668     9/5/09 11:30                 9/5/09   \n",
       "1           2    MBY005712    9/13/09 17:30                9/13/09   \n",
       "2           3    MBY005713     9/14/09 9:30                9/14/09   \n",
       "3           4    MBY005730    9/18/09 12:30                9/18/09   \n",
       "4           6    MBY005764    9/28/09 10:30                9/28/09   \n",
       "\n",
       "                  venue_x    address_name_x               street_x  \\\n",
       "0  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library   \n",
       "1  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library   \n",
       "2  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library   \n",
       "3  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library   \n",
       "4  MobileBooth West (MBY)  MobileBooth West         Public Library   \n",
       "\n",
       "             city_x state_/_province_x  postal_code_x  ...  \\\n",
       "0            Paonia                 CO        81428.0  ...   \n",
       "1            Paonia                 CO        81428.0  ...   \n",
       "2            Paonia                 CO        81428.0  ...   \n",
       "3            Paonia                 CO        81428.0  ...   \n",
       "4  Colorado Springs                 CO        80911.0  ...   \n",
       "\n",
       "  interviewer_relationship_1_to_storyteller_1_y language_1_y  \\\n",
       "0                                          wife      Spanish   \n",
       "1                                        esposa      Spanish   \n",
       "2                                   grandmother      English   \n",
       "3                                        friend          NaN   \n",
       "4                                        friend          NaN   \n",
       "\n",
       "                         keywords_-_fixed_subjects_y  \\\n",
       "0  Achievements and Awards\\n\\nChildren\\n\\nCommuni...   \n",
       "1  Anniversaries\\n\\nChildren\\n\\nCommunity Busines...   \n",
       "2  Birth\\n\\nBurials\\n\\nCancer\\n\\nChildcare\\n\\nChi...   \n",
       "3  Changes In Education\\n\\nCommunity Businesses\\n...   \n",
       "4  Education\\n\\nAchievements and Awards\\n\\nArmy\\n...   \n",
       "\n",
       "                                keywords_-_general_y label1-fs     label2-fs  \\\n",
       "0  bilingual\\n\\nBilingue\\n\\nChihuahua, Mexico\\n\\n...  Children  Workday Life   \n",
       "1  accidents\\n\\nbaile\\n\\ncar accident\\n\\ncemetery...  Children  Workday Life   \n",
       "2  alcohol\\n\\nbirth of first child\\n\\nchemotherap...   Parents      Children   \n",
       "3  anecdotes (humorous but true stories)\\n\\nappea...   Parents       Schools   \n",
       "4  advocacy\\n\\nadvocate\\n\\ncollege\\n\\ndevelopment...   Schools      Children   \n",
       "\n",
       "             label3-fs                      label1-g  \\\n",
       "0  Immigration Stories  social beliefs and practices   \n",
       "1  Immigration Stories      memories of former times   \n",
       "2             Marriage        memories of growing up   \n",
       "3         Workday Life        memories of growing up   \n",
       "4         Workday Life      memories of former times   \n",
       "\n",
       "                       label2-g                  label3-g  \n",
       "0                     ethnicity  memories of former times  \n",
       "1                        spouse          family tradition  \n",
       "2      memories of former times          family tradition  \n",
       "3  social beliefs and practices                 ethnicity  \n",
       "4           school day memories                    spouse  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = transcript_raw.merge(label_raw, on='interview_id')\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(332, 84)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>google_transcript</th>\n",
       "      <th>label1-g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I mean I'm already so my lawyer Singapore and ...</td>\n",
       "      <td>social beliefs and practices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>okay mean Hombres es el Amante Samira cincuent...</td>\n",
       "      <td>memories of former times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my name is Melissa Humphrey I'm 26 today's dat...</td>\n",
       "      <td>memories of growing up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello my name is Adolfo Carranza Junior and I'...</td>\n",
       "      <td>memories of growing up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my number is rational and pony my name is Rose...</td>\n",
       "      <td>memories of former times</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   google_transcript  \\\n",
       "0  I mean I'm already so my lawyer Singapore and ...   \n",
       "1  okay mean Hombres es el Amante Samira cincuent...   \n",
       "2  my name is Melissa Humphrey I'm 26 today's dat...   \n",
       "3  hello my name is Adolfo Carranza Junior and I'...   \n",
       "4  my number is rational and pony my name is Rose...   \n",
       "\n",
       "                       label1-g  \n",
       "0  social beliefs and practices  \n",
       "1      memories of former times  \n",
       "2        memories of growing up  \n",
       "3        memories of growing up  \n",
       "4      memories of former times  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = train_raw[['google_transcript', LABEL]]\n",
    "train_raw.reset_index(inplace=True, drop=True)\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anecdotes (humorous but true stories)\n",
      "ethnicity\n",
      "memories of former times\n",
      "memories of growing up\n",
      "social beliefs and practices\n"
     ]
    }
   ],
   "source": [
    "for l in np.unique(train_raw[LABEL]):\n",
    "  print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I mean I'm already so my lawyer Singapore and ...</td>\n",
       "      <td>social beliefs and practices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>okay mean Hombres es el Amante Samira cincuent...</td>\n",
       "      <td>memories of former times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my name is Melissa Humphrey I'm 26 today's dat...</td>\n",
       "      <td>memories of growing up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello my name is Adolfo Carranza Junior and I'...</td>\n",
       "      <td>memories of growing up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my number is rational and pony my name is Rose...</td>\n",
       "      <td>memories of former times</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I mean I'm already so my lawyer Singapore and ...   \n",
       "1  okay mean Hombres es el Amante Samira cincuent...   \n",
       "2  my name is Melissa Humphrey I'm 26 today's dat...   \n",
       "3  hello my name is Adolfo Carranza Junior and I'...   \n",
       "4  my number is rational and pony my name is Rose...   \n",
       "\n",
       "                          label  \n",
       "0  social beliefs and practices  \n",
       "1      memories of former times  \n",
       "2        memories of growing up  \n",
       "3        memories of growing up  \n",
       "4      memories of former times  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw=train_raw.rename(columns = {'google_transcript':'text', LABEL:'label'})\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I mean I'm already so my lawyer Singapore and ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>okay mean Hombres es el Amante Samira cincuent...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my name is Melissa Humphrey I'm 26 today's dat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello my name is Adolfo Carranza Junior and I'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my number is rational and pony my name is Rose...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I mean I'm already so my lawyer Singapore and ...      4\n",
       "1  okay mean Hombres es el Amante Samira cincuent...      2\n",
       "2  my name is Melissa Humphrey I'm 26 today's dat...      3\n",
       "3  hello my name is Adolfo Carranza Junior and I'...      3\n",
       "4  my number is rational and pony my name is Rose...      2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "LE = LabelEncoder()\n",
    "train_raw['label'] = LE.fit_transform(train_raw['label'])\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(np.unique(train_raw['label']))\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r = train_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hello I'm Rick Palmer I'm 57 years old today i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>my name is Linda Vasquez my age is 47 years ol...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>good morning my name is Dorothy Archuleta 871 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>my name is Lily Sullivan I am 26 years old tod...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>my name is Steven A Castillo age 56 today's da...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "6    hello I'm Rick Palmer I'm 57 years old today i...      3\n",
       "307  my name is Linda Vasquez my age is 47 years ol...      3\n",
       "5    good morning my name is Dorothy Archuleta 871 ...      3\n",
       "254  my name is Lily Sullivan I am 26 years old tod...      4\n",
       "289  my name is Steven A Castillo age 56 today's da...      3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_r = train_r.reindex(np.random.permutation(train_r.index))\n",
    "train_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_txt(text):\n",
    "  text = re.sub(\"'\", \"\",text)\n",
    "  text=re.sub(\"(\\\\W)+\",\" \",text)    \n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hello Im Rick Palmer Im 57 years old today is ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>my name is Linda Vasquez my age is 47 years ol...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>good morning my name is Dorothy Archuleta 871 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>my name is Lily Sullivan I am 26 years old tod...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>my name is Steven A Castillo age 56 todays dat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "6    hello Im Rick Palmer Im 57 years old today is ...      3\n",
       "307  my name is Linda Vasquez my age is 47 years ol...      3\n",
       "5    good morning my name is Dorothy Archuleta 871 ...      3\n",
       "254  my name is Lily Sullivan I am 26 years old tod...      4\n",
       "289  my name is Steven A Castillo age 56 todays dat...      3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_r['text']  = train_r.text.apply(clean_txt)\n",
    "train_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>my name is Cindy Mosqueda Im 29 years old toda...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>hello my name is Ernesto Cassidys Im 25 years ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>hi Im Angela Rodriguez Im 36 today is April 17...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>hello my name is Jonathan malacarne Im 32 year...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>good afternoon my name is Stephanie Lorraine p...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "107  my name is Cindy Mosqueda Im 29 years old toda...      3\n",
       "237  hello my name is Ernesto Cassidys Im 25 years ...      3\n",
       "247  hi Im Angela Rodriguez Im 36 today is April 17...      3\n",
       "123  hello my name is Jonathan malacarne Im 32 year...      3\n",
       "81   good afternoon my name is Stephanie Lorraine p...      4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(train_r, test_size=0.2)\n",
    "while(len(np.unique(train.label)) != num_labels):\n",
    "      train, val = train_test_split(train_r, test_size=0.2)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my name is Cindy Mosqueda Im 29 years old toda...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello my name is Ernesto Cassidys Im 25 years ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  my name is Cindy Mosqueda Im 29 years old toda...      3\n",
       "1  hello my name is Ernesto Cassidys Im 25 years ...      3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.reset_index(drop=True, inplace=True)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pronombres Victoria Fernandez tengo ciento sei...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my name is Loretta Martinez Williams my age is...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  pronombres Victoria Fernandez tengo ciento sei...      3\n",
       "1  my name is Loretta Martinez Williams my age is...      3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.reset_index(drop=True, inplace=True)\n",
    "val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67, 2), (265, 2))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-tensorflow in c:\\users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages (from bert-tensorflow) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "#Installing BERT module\n",
    "!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Importing BERT modules\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Model output directory: ./bert_output/ *****\n"
     ]
    }
   ],
   "source": [
    "# Set the output directory for saving model file\n",
    "OUTPUT_DIR = './bert_output/'\n",
    "\n",
    "#@markdown Whether or not to clear/delete the directory and create a new one\n",
    "DO_DELETE = True #@param {type:\"boolean\"}\n",
    "\n",
    "if DO_DELETE:\n",
    "  try:\n",
    "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape : (265, 2)\n",
      "Validation Set Shape : (67, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Shape :\", train.shape)\n",
    "print(\"Validation Set Shape :\", val.shape)\n",
    "# print(\"Test Set Shape :\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_COLUMN = 'text'\n",
    "LABEL_COLUMN = 'label'\n",
    "# The list containing all the classes (train['SECTION'].unique())\n",
    "label_list = [x for x in np.unique(train.label)]\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(text1):\n",
    "  l_total = []\n",
    "  l_parcial = []\n",
    "  if len(text1.split())//150 >0:\n",
    "    n = len(text1.split())//150\n",
    "  else: \n",
    "    n = 1\n",
    "  for w in range(n):\n",
    "    if w == 0:\n",
    "      l_parcial = text1.split()[:200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "    else:\n",
    "      l_parcial = text1.split()[w*150:w*150 + 200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "  return l_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my name is Cindy Mosqueda Im 29 years old toda...</td>\n",
       "      <td>3</td>\n",
       "      <td>[my name is Cindy Mosqueda Im 29 years old tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello my name is Ernesto Cassidys Im 25 years ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[hello my name is Ernesto Cassidys Im 25 years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hi Im Angela Rodriguez Im 36 today is April 17...</td>\n",
       "      <td>3</td>\n",
       "      <td>[hi Im Angela Rodriguez Im 36 today is April 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello my name is Jonathan malacarne Im 32 year...</td>\n",
       "      <td>3</td>\n",
       "      <td>[hello my name is Jonathan malacarne Im 32 yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good afternoon my name is Stephanie Lorraine p...</td>\n",
       "      <td>4</td>\n",
       "      <td>[good afternoon my name is Stephanie Lorraine ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  my name is Cindy Mosqueda Im 29 years old toda...      3   \n",
       "1  hello my name is Ernesto Cassidys Im 25 years ...      3   \n",
       "2  hi Im Angela Rodriguez Im 36 today is April 17...      3   \n",
       "3  hello my name is Jonathan malacarne Im 32 year...      3   \n",
       "4  good afternoon my name is Stephanie Lorraine p...      4   \n",
       "\n",
       "                                          text_split  \n",
       "0  [my name is Cindy Mosqueda Im 29 years old tod...  \n",
       "1  [hello my name is Ernesto Cassidys Im 25 years...  \n",
       "2  [hi Im Angela Rodriguez Im 36 today is April 1...  \n",
       "3  [hello my name is Jonathan malacarne Im 32 yea...  \n",
       "4  [good afternoon my name is Stephanie Lorraine ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text_split'] = train[DATA_COLUMN].apply(get_split)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pronombres Victoria Fernandez tengo ciento sei...</td>\n",
       "      <td>3</td>\n",
       "      <td>[pronombres Victoria Fernandez tengo ciento se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my name is Loretta Martinez Williams my age is...</td>\n",
       "      <td>3</td>\n",
       "      <td>[my name is Loretta Martinez Williams my age i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  pronombres Victoria Fernandez tengo ciento sei...      3   \n",
       "1  my name is Loretta Martinez Williams my age is...      3   \n",
       "\n",
       "                                          text_split  \n",
       "0  [pronombres Victoria Fernandez tengo ciento se...  \n",
       "1  [my name is Loretta Martinez Williams my age i...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['text_split'] = val[DATA_COLUMN].apply(get_split)\n",
    "val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7859, 7859, 7859)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_l = []\n",
    "label_l = []\n",
    "index_l =[]\n",
    "for idx,row in train.iterrows():\n",
    "  for l in row['text_split']:\n",
    "    train_l.append(l)\n",
    "    label_l.append(row['label'])\n",
    "    index_l.append(idx)\n",
    "len(train_l), len(label_l), len(index_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1972, 1972, 1972)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_l = []\n",
    "val_label_l = []\n",
    "val_index_l = []\n",
    "for idx,row in val.iterrows():\n",
    "  for l in row['text_split']:\n",
    "    val_l.append(l)\n",
    "    val_label_l.append(row['label'])\n",
    "    val_index_l.append(idx)\n",
    "len(val_l), len(val_label_l), len(val_index_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my name is Cindy Mosqueda Im 29 years old toda...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was born in your parents my parents are or w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and my mother was living in town so they met b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>go do you want most of this is what Ive been t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>me we were so so poor that my mother used to a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  my name is Cindy Mosqueda Im 29 years old toda...      3\n",
       "1  I was born in your parents my parents are or w...      3\n",
       "2  and my mother was living in town so they met b...      3\n",
       "3  go do you want most of this is what Ive been t...      3\n",
       "4  me we were so so poor that my mother used to a...      3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame({DATA_COLUMN:train_l, LABEL_COLUMN:label_l})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pronombres Victoria Fernandez tengo ciento sei...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>look at your age latterly he on the Nephron go...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>at El Pollo come on okay we will need NES to E...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>safe and Jose Casado because I dont even matri...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>staff we must we must we must have a Tomar fot...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  pronombres Victoria Fernandez tengo ciento sei...      3\n",
       "1  look at your age latterly he on the Nephron go...      3\n",
       "2  at El Pollo come on okay we will need NES to E...      3\n",
       "3  safe and Jose Casado because I dont even matri...      3\n",
       "4  staff we must we must we must have a Tomar fot...      3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.DataFrame({DATA_COLUMN:val_l, LABEL_COLUMN:val_label_l})\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_InputExamples = train_df.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "val_InputExamples = val_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       <bert.run_classifier.InputExample object at 0x...\n",
       "1       <bert.run_classifier.InputExample object at 0x...\n",
       "2       <bert.run_classifier.InputExample object at 0x...\n",
       "3       <bert.run_classifier.InputExample object at 0x...\n",
       "4       <bert.run_classifier.InputExample object at 0x...\n",
       "                              ...                        \n",
       "7854    <bert.run_classifier.InputExample object at 0x...\n",
       "7855    <bert.run_classifier.InputExample object at 0x...\n",
       "7856    <bert.run_classifier.InputExample object at 0x...\n",
       "7857    <bert.run_classifier.InputExample object at 0x...\n",
       "7858    <bert.run_classifier.InputExample object at 0x...\n",
       "Length: 7859, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 - guid of training set :  None\n",
      "\n",
      "__________\n",
      "Row 0 - text_a of training set :  my name is Cindy Mosqueda Im 29 years old today is February 11th 2010 I am in East LA and Im here with my father Carlos Mosqueda my name is Carlo Mosqueda Midas 56 today is February 11th 2010 and we are at East LA and I am with my daughter Cindy muscular all right Dad so I could thank you for agreeing to come and be here with me I wanted to ask you just can you describe you just tell me where youre from like where did you where were you born where did you grow up I was born in Salamanca Guanajuato Mexico I believe I was born in a home and in the house I dont have any recollection of my parents saying that they took me to Any House in the in the hospital or that I was one of the hospital so thats where I was born in your parents my parents are or were they are both deceased rest in peace Bartolo and wanna muscella who did the how long did you live in Salamanca is that where you grew up the whole time until I was age 686 my parents decided to\n",
      "\n",
      "__________\n",
      "Row 0 - text_b of training set :  None\n",
      "\n",
      "__________\n",
      "Row 0 - label of training set :  3\n"
     ]
    }
   ],
   "source": [
    "print(\"Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n",
    "print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples.iloc[0].text_a)\n",
    "print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples.iloc[0].text_b)\n",
    "print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples.iloc[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'name', 'is', 'cindy', 'mosque', '##da', 'im', '29', 'years', 'old', 'today', 'is', 'february', '11th', '2010', 'i', 'am', 'in', 'east', 'la', 'and', 'im', 'here', 'with', 'my', 'father', 'carlos', 'mosque', '##da', 'my', 'name', 'is', 'carlo', 'mosque', '##da', 'mid', '##as', '56', 'today', 'is', 'february', '11th', '2010', 'and', 'we', 'are', 'at', 'east', 'la', 'and', 'i', 'am', 'with', 'my', 'daughter', 'cindy', 'muscular', 'all', 'right', 'dad', 'so', 'i', 'could', 'thank', 'you', 'for', 'agreeing', 'to', 'come', 'and', 'be', 'here', 'with', 'me', 'i', 'wanted', 'to', 'ask', 'you', 'just', 'can', 'you', 'describe', 'you', 'just', 'tell', 'me', 'where', 'your', '##e', 'from', 'like', 'where', 'did', 'you', 'where', 'were', 'you', 'born', 'where', 'did', 'you', 'grow', 'up', 'i', 'was', 'born', 'in', 'salamanca', 'gu', '##ana', '##ju', '##ato', 'mexico', 'i', 'believe', 'i', 'was', 'born', 'in', 'a', 'home', 'and', 'in', 'the', 'house', 'i', 'don', '##t', 'have', 'any', 'rec', '##oll', '##ection', 'of', 'my', 'parents', 'saying', 'that', 'they', 'took', 'me', 'to', 'any', 'house', 'in', 'the', 'in', 'the', 'hospital', 'or', 'that', 'i', 'was', 'one', 'of', 'the', 'hospital', 'so', 'that', '##s', 'where', 'i', 'was', 'born', 'in', 'your', 'parents', 'my', 'parents', 'are', 'or', 'were', 'they', 'are', 'both', 'deceased', 'rest', 'in', 'peace', 'bart', '##olo', 'and', 'wanna', 'mu', '##sc', '##ella', 'who', 'did', 'the', 'how', 'long', 'did', 'you', 'live', 'in', 'salamanca', 'is', 'that', 'where', 'you', 'grew', 'up', 'the', 'whole', 'time', 'until', 'i', 'was', 'age', '68', '##6', 'my', 'parents', 'decided', 'to']\n"
     ]
    }
   ],
   "source": [
    "#Here is what the tokenised sample of the first training set observation looks like\n",
    "print(tokenizer.tokenize(train_InputExamples.iloc[0].text_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 7859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 7859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] my name is cindy mosque ##da im 29 years old today is february 11th 2010 i am in east la and im here with my father carlos mosque ##da my name is carlo mosque ##da mid ##as 56 today is february 11th 2010 and we are at east la and i am with my daughter cindy muscular all right dad so i could thank you for agreeing to come and be here with me i wanted to ask you just can you describe you just tell me where your ##e from like where did you where were you born where did you grow up i was born in salamanca gu ##ana ##ju ##ato mexico i believe i was born in a home and in the house i don ##t have any rec ##oll ##ection of my parents saying that they took me to any house in the in the hospital or that i was one of the hospital so that ##s where i was born in your parents my parents are or were they are both deceased rest in peace bart ##olo and wanna mu ##sc ##ella who did the how long did you live in salamanca is [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] my name is cindy mosque ##da im 29 years old today is february 11th 2010 i am in east la and im here with my father carlos mosque ##da my name is carlo mosque ##da mid ##as 56 today is february 11th 2010 and we are at east la and i am with my daughter cindy muscular all right dad so i could thank you for agreeing to come and be here with me i wanted to ask you just can you describe you just tell me where your ##e from like where did you where were you born where did you grow up i was born in salamanca gu ##ana ##ju ##ato mexico i believe i was born in a home and in the house i don ##t have any rec ##oll ##ection of my parents saying that they took me to any house in the in the hospital or that i was one of the hospital so that ##s where i was born in your parents my parents are or were they are both deceased rest in peace bart ##olo and wanna mu ##sc ##ella who did the how long did you live in salamanca is [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2026 2171 2003 15837 8806 2850 10047 2756 2086 2214 2651 2003 2337 6252 2230 1045 2572 1999 2264 2474 1998 10047 2182 2007 2026 2269 5828 8806 2850 2026 2171 2003 9758 8806 2850 3054 3022 5179 2651 2003 2337 6252 2230 1998 2057 2024 2012 2264 2474 1998 1045 2572 2007 2026 2684 15837 13472 2035 2157 3611 2061 1045 2071 4067 2017 2005 16191 2000 2272 1998 2022 2182 2007 2033 1045 2359 2000 3198 2017 2074 2064 2017 6235 2017 2074 2425 2033 2073 2115 2063 2013 2066 2073 2106 2017 2073 2020 2017 2141 2073 2106 2017 4982 2039 1045 2001 2141 1999 29608 19739 5162 9103 10610 3290 1045 2903 1045 2001 2141 1999 1037 2188 1998 1999 1996 2160 1045 2123 2102 2031 2151 28667 14511 18491 1997 2026 3008 3038 2008 2027 2165 2033 2000 2151 2160 1999 1996 1999 1996 2902 2030 2008 1045 2001 2028 1997 1996 2902 2061 2008 2015 2073 1045 2001 2141 1999 2115 3008 2026 3008 2024 2030 2020 2027 2024 2119 10181 2717 1999 3521 12075 12898 1998 10587 14163 11020 8411 2040 2106 1996 2129 2146 2106 2017 2444 1999 29608 2003 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2026 2171 2003 15837 8806 2850 10047 2756 2086 2214 2651 2003 2337 6252 2230 1045 2572 1999 2264 2474 1998 10047 2182 2007 2026 2269 5828 8806 2850 2026 2171 2003 9758 8806 2850 3054 3022 5179 2651 2003 2337 6252 2230 1998 2057 2024 2012 2264 2474 1998 1045 2572 2007 2026 2684 15837 13472 2035 2157 3611 2061 1045 2071 4067 2017 2005 16191 2000 2272 1998 2022 2182 2007 2033 1045 2359 2000 3198 2017 2074 2064 2017 6235 2017 2074 2425 2033 2073 2115 2063 2013 2066 2073 2106 2017 2073 2020 2017 2141 2073 2106 2017 4982 2039 1045 2001 2141 1999 29608 19739 5162 9103 10610 3290 1045 2903 1045 2001 2141 1999 1037 2188 1998 1999 1996 2160 1045 2123 2102 2031 2151 28667 14511 18491 1997 2026 3008 3038 2008 2027 2165 2033 2000 2151 2160 1999 1996 1999 1996 2902 2030 2008 1045 2001 2028 1997 1996 2902 2061 2008 2015 2073 1045 2001 2141 1999 2115 3008 2026 3008 2024 2030 2020 2027 2024 2119 10181 2717 1999 3521 12075 12898 1998 10587 14163 11020 8411 2040 2106 1996 2129 2146 2106 2017 2444 1999 29608 2003 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i was born in your parents my parents are or were they are both deceased rest in peace bart ##olo and wanna mu ##sc ##ella who did the how long did you live in salamanca is that where you grew up the whole time until i was age 68 ##6 my parents decided to im ##mi ##grate to the united states and that ##s how i was about six years old when we came here when your parents are whole family everybody we are eight siblings i have five sisters and two brothers and mom and dad we all came together same time and where did you first go to do you remember what it was like when you left them on college what they told you what what happened with grandpa and grandma doing southern manga do you remember what my father was from the farming industry he was he used to live in on rancho and my mother was living in town so they met because my dad used to have to go to town from time to time and that ##s how they met he wasn ##t very well liked of course because he was [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i was born in your parents my parents are or were they are both deceased rest in peace bart ##olo and wanna mu ##sc ##ella who did the how long did you live in salamanca is that where you grew up the whole time until i was age 68 ##6 my parents decided to im ##mi ##grate to the united states and that ##s how i was about six years old when we came here when your parents are whole family everybody we are eight siblings i have five sisters and two brothers and mom and dad we all came together same time and where did you first go to do you remember what it was like when you left them on college what they told you what what happened with grandpa and grandma doing southern manga do you remember what my father was from the farming industry he was he used to live in on rancho and my mother was living in town so they met because my dad used to have to go to town from time to time and that ##s how they met he wasn ##t very well liked of course because he was [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2001 2141 1999 2115 3008 2026 3008 2024 2030 2020 2027 2024 2119 10181 2717 1999 3521 12075 12898 1998 10587 14163 11020 8411 2040 2106 1996 2129 2146 2106 2017 2444 1999 29608 2003 2008 2073 2017 3473 2039 1996 2878 2051 2127 1045 2001 2287 6273 2575 2026 3008 2787 2000 10047 4328 22780 2000 1996 2142 2163 1998 2008 2015 2129 1045 2001 2055 2416 2086 2214 2043 2057 2234 2182 2043 2115 3008 2024 2878 2155 7955 2057 2024 2809 9504 1045 2031 2274 5208 1998 2048 3428 1998 3566 1998 3611 2057 2035 2234 2362 2168 2051 1998 2073 2106 2017 2034 2175 2000 2079 2017 3342 2054 2009 2001 2066 2043 2017 2187 2068 2006 2267 2054 2027 2409 2017 2054 2054 3047 2007 15310 1998 13055 2725 2670 8952 2079 2017 3342 2054 2026 2269 2001 2013 1996 7876 3068 2002 2001 2002 2109 2000 2444 1999 2006 18123 1998 2026 2388 2001 2542 1999 2237 2061 2027 2777 2138 2026 3611 2109 2000 2031 2000 2175 2000 2237 2013 2051 2000 2051 1998 2008 2015 2129 2027 2777 2002 2347 2102 2200 2092 4669 1997 2607 2138 2002 2001 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 2001 2141 1999 2115 3008 2026 3008 2024 2030 2020 2027 2024 2119 10181 2717 1999 3521 12075 12898 1998 10587 14163 11020 8411 2040 2106 1996 2129 2146 2106 2017 2444 1999 29608 2003 2008 2073 2017 3473 2039 1996 2878 2051 2127 1045 2001 2287 6273 2575 2026 3008 2787 2000 10047 4328 22780 2000 1996 2142 2163 1998 2008 2015 2129 1045 2001 2055 2416 2086 2214 2043 2057 2234 2182 2043 2115 3008 2024 2878 2155 7955 2057 2024 2809 9504 1045 2031 2274 5208 1998 2048 3428 1998 3566 1998 3611 2057 2035 2234 2362 2168 2051 1998 2073 2106 2017 2034 2175 2000 2079 2017 3342 2054 2009 2001 2066 2043 2017 2187 2068 2006 2267 2054 2027 2409 2017 2054 2054 3047 2007 15310 1998 13055 2725 2670 8952 2079 2017 3342 2054 2026 2269 2001 2013 1996 7876 3068 2002 2001 2002 2109 2000 2444 1999 2006 18123 1998 2026 2388 2001 2542 1999 2237 2061 2027 2777 2138 2026 3611 2109 2000 2031 2000 2175 2000 2237 2013 2051 2000 2051 1998 2008 2015 2129 2027 2777 2002 2347 2102 2200 2092 4669 1997 2607 2138 2002 2001 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] and my mother was living in town so they met because my dad used to have to go to town from time to time and that ##s how they met he wasn ##t very well liked of course because he was from the el rancho and my mother falls from the town so there were people that didn ##t like him these to throw rocks at his feet trying to pick fights nevertheless that they got married and they had us and decided to move on but my dad at one time worked in the can ##nery the fish my mother that i know of never worked outside of the home she did work as a seam ##st ##ress she was very good at it but she did that pretty much at home but i know she never worked outside of the home so you went from salamanca did you guys drive lam ##onic ##a to where ##d you go do you want most of this is what iv ##e been told because i don ##t remember everything tonight so we we road by bus or train to pie ##dra ##s ne ##gra ##s why is it on [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] and my mother was living in town so they met because my dad used to have to go to town from time to time and that ##s how they met he wasn ##t very well liked of course because he was from the el rancho and my mother falls from the town so there were people that didn ##t like him these to throw rocks at his feet trying to pick fights nevertheless that they got married and they had us and decided to move on but my dad at one time worked in the can ##nery the fish my mother that i know of never worked outside of the home she did work as a seam ##st ##ress she was very good at it but she did that pretty much at home but i know she never worked outside of the home so you went from salamanca did you guys drive lam ##onic ##a to where ##d you go do you want most of this is what iv ##e been told because i don ##t remember everything tonight so we we road by bus or train to pie ##dra ##s ne ##gra ##s why is it on [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1998 2026 2388 2001 2542 1999 2237 2061 2027 2777 2138 2026 3611 2109 2000 2031 2000 2175 2000 2237 2013 2051 2000 2051 1998 2008 2015 2129 2027 2777 2002 2347 2102 2200 2092 4669 1997 2607 2138 2002 2001 2013 1996 3449 18123 1998 2026 2388 4212 2013 1996 2237 2061 2045 2020 2111 2008 2134 2102 2066 2032 2122 2000 5466 5749 2012 2010 2519 2667 2000 4060 9590 6600 2008 2027 2288 2496 1998 2027 2018 2149 1998 2787 2000 2693 2006 2021 2026 3611 2012 2028 2051 2499 1999 1996 2064 27415 1996 3869 2026 2388 2008 1045 2113 1997 2196 2499 2648 1997 1996 2188 2016 2106 2147 2004 1037 25180 3367 8303 2016 2001 2200 2204 2012 2009 2021 2016 2106 2008 3492 2172 2012 2188 2021 1045 2113 2016 2196 2499 2648 1997 1996 2188 2061 2017 2253 2013 29608 2106 2017 4364 3298 16983 12356 2050 2000 2073 2094 2017 2175 2079 2017 2215 2087 1997 2023 2003 2054 4921 2063 2042 2409 2138 1045 2123 2102 3342 2673 3892 2061 2057 2057 2346 2011 3902 2030 3345 2000 11345 7265 2015 11265 17643 2015 2339 2003 2009 2006 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1998 2026 2388 2001 2542 1999 2237 2061 2027 2777 2138 2026 3611 2109 2000 2031 2000 2175 2000 2237 2013 2051 2000 2051 1998 2008 2015 2129 2027 2777 2002 2347 2102 2200 2092 4669 1997 2607 2138 2002 2001 2013 1996 3449 18123 1998 2026 2388 4212 2013 1996 2237 2061 2045 2020 2111 2008 2134 2102 2066 2032 2122 2000 5466 5749 2012 2010 2519 2667 2000 4060 9590 6600 2008 2027 2288 2496 1998 2027 2018 2149 1998 2787 2000 2693 2006 2021 2026 3611 2012 2028 2051 2499 1999 1996 2064 27415 1996 3869 2026 2388 2008 1045 2113 1997 2196 2499 2648 1997 1996 2188 2016 2106 2147 2004 1037 25180 3367 8303 2016 2001 2200 2204 2012 2009 2021 2016 2106 2008 3492 2172 2012 2188 2021 1045 2113 2016 2196 2499 2648 1997 1996 2188 2061 2017 2253 2013 29608 2106 2017 4364 3298 16983 12356 2050 2000 2073 2094 2017 2175 2079 2017 2215 2087 1997 2023 2003 2054 4921 2063 2042 2409 2138 1045 2123 2102 3342 2673 3892 2061 2057 2057 2346 2011 3902 2030 3345 2000 11345 7265 2015 11265 17643 2015 2339 2003 2009 2006 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] go do you want most of this is what iv ##e been told because i don ##t remember everything tonight so we we road by bus or train to pie ##dra ##s ne ##gra ##s why is it on the border on the border border town of get that iv ##e ni ##gga ##s and we cross our border and and we cross that browns ##ville texas and we lived in texas for about 3 years in a dairy farm who is that like it was exciting it was im going to go back a little bit because because i think this is important my parents didn ##t have anything they came from the known to the unknown and they left everything i decided to take a big big huge risk on airline and when they moved course they didn ##t have any money so when were in the border town in mexico i recall that my my mother used to ask me we were so so poor that my mother used to ask me to go go see dad cu ##z my dad work at a gas station and to go see him to see if he [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] go do you want most of this is what iv ##e been told because i don ##t remember everything tonight so we we road by bus or train to pie ##dra ##s ne ##gra ##s why is it on the border on the border border town of get that iv ##e ni ##gga ##s and we cross our border and and we cross that browns ##ville texas and we lived in texas for about 3 years in a dairy farm who is that like it was exciting it was im going to go back a little bit because because i think this is important my parents didn ##t have anything they came from the known to the unknown and they left everything i decided to take a big big huge risk on airline and when they moved course they didn ##t have any money so when were in the border town in mexico i recall that my my mother used to ask me we were so so poor that my mother used to ask me to go go see dad cu ##z my dad work at a gas station and to go see him to see if he [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2175 2079 2017 2215 2087 1997 2023 2003 2054 4921 2063 2042 2409 2138 1045 2123 2102 3342 2673 3892 2061 2057 2057 2346 2011 3902 2030 3345 2000 11345 7265 2015 11265 17643 2015 2339 2003 2009 2006 1996 3675 2006 1996 3675 3675 2237 1997 2131 2008 4921 2063 9152 23033 2015 1998 2057 2892 2256 3675 1998 1998 2057 2892 2008 13240 3077 3146 1998 2057 2973 1999 3146 2005 2055 1017 2086 1999 1037 11825 3888 2040 2003 2008 2066 2009 2001 10990 2009 2001 10047 2183 2000 2175 2067 1037 2210 2978 2138 2138 1045 2228 2023 2003 2590 2026 3008 2134 2102 2031 2505 2027 2234 2013 1996 2124 2000 1996 4242 1998 2027 2187 2673 1045 2787 2000 2202 1037 2502 2502 4121 3891 2006 8582 1998 2043 2027 2333 2607 2027 2134 2102 2031 2151 2769 2061 2043 2020 1999 1996 3675 2237 1999 3290 1045 9131 2008 2026 2026 2388 2109 2000 3198 2033 2057 2020 2061 2061 3532 2008 2026 2388 2109 2000 3198 2033 2000 2175 2175 2156 3611 12731 2480 2026 3611 2147 2012 1037 3806 2276 1998 2000 2175 2156 2032 2000 2156 2065 2002 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2175 2079 2017 2215 2087 1997 2023 2003 2054 4921 2063 2042 2409 2138 1045 2123 2102 3342 2673 3892 2061 2057 2057 2346 2011 3902 2030 3345 2000 11345 7265 2015 11265 17643 2015 2339 2003 2009 2006 1996 3675 2006 1996 3675 3675 2237 1997 2131 2008 4921 2063 9152 23033 2015 1998 2057 2892 2256 3675 1998 1998 2057 2892 2008 13240 3077 3146 1998 2057 2973 1999 3146 2005 2055 1017 2086 1999 1037 11825 3888 2040 2003 2008 2066 2009 2001 10990 2009 2001 10047 2183 2000 2175 2067 1037 2210 2978 2138 2138 1045 2228 2023 2003 2590 2026 3008 2134 2102 2031 2505 2027 2234 2013 1996 2124 2000 1996 4242 1998 2027 2187 2673 1045 2787 2000 2202 1037 2502 2502 4121 3891 2006 8582 1998 2043 2027 2333 2607 2027 2134 2102 2031 2151 2769 2061 2043 2020 1999 1996 3675 2237 1999 3290 1045 9131 2008 2026 2026 2388 2109 2000 3198 2033 2057 2020 2061 2061 3532 2008 2026 2388 2109 2000 3198 2033 2000 2175 2175 2156 3611 12731 2480 2026 3611 2147 2012 1037 3806 2276 1998 2000 2175 2156 2032 2000 2156 2065 2002 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] me we were so so poor that my mother used to ask me to go go see dad cu ##z my dad work at a gas station and to go see him to see if he had money to be able to buy tor ##till ##as for the day and she i remember that very vivid ##ly it wasn ##t very far cu ##z i don ##t remember how far it took me to get there but i do remember that happening and my dad was up very blessed we are very blessed and my dad met somebody that happened to be in the military that used to come in as a client and that person was the one that actually helped them start the transition to get us immigrated into the united states it was actually a client of the service station that came in that open the doors and we live in a dairy farm the dairy farm was one of the most wonderful experiences iv ##e ever had in my life because to this day to this day i will go out of my way and she know where our office is at to drive [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] me we were so so poor that my mother used to ask me to go go see dad cu ##z my dad work at a gas station and to go see him to see if he had money to be able to buy tor ##till ##as for the day and she i remember that very vivid ##ly it wasn ##t very far cu ##z i don ##t remember how far it took me to get there but i do remember that happening and my dad was up very blessed we are very blessed and my dad met somebody that happened to be in the military that used to come in as a client and that person was the one that actually helped them start the transition to get us immigrated into the united states it was actually a client of the service station that came in that open the doors and we live in a dairy farm the dairy farm was one of the most wonderful experiences iv ##e ever had in my life because to this day to this day i will go out of my way and she know where our office is at to drive [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2033 2057 2020 2061 2061 3532 2008 2026 2388 2109 2000 3198 2033 2000 2175 2175 2156 3611 12731 2480 2026 3611 2147 2012 1037 3806 2276 1998 2000 2175 2156 2032 2000 2156 2065 2002 2018 2769 2000 2022 2583 2000 4965 17153 28345 3022 2005 1996 2154 1998 2016 1045 3342 2008 2200 14954 2135 2009 2347 2102 2200 2521 12731 2480 1045 2123 2102 3342 2129 2521 2009 2165 2033 2000 2131 2045 2021 1045 2079 3342 2008 6230 1998 2026 3611 2001 2039 2200 10190 2057 2024 2200 10190 1998 2026 3611 2777 8307 2008 3047 2000 2022 1999 1996 2510 2008 2109 2000 2272 1999 2004 1037 7396 1998 2008 2711 2001 1996 2028 2008 2941 3271 2068 2707 1996 6653 2000 2131 2149 17352 2046 1996 2142 2163 2009 2001 2941 1037 7396 1997 1996 2326 2276 2008 2234 1999 2008 2330 1996 4303 1998 2057 2444 1999 1037 11825 3888 1996 11825 3888 2001 2028 1997 1996 2087 6919 6322 4921 2063 2412 2018 1999 2026 2166 2138 2000 2023 2154 2000 2023 2154 1045 2097 2175 2041 1997 2026 2126 1998 2016 2113 2073 2256 2436 2003 2012 2000 3298 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2033 2057 2020 2061 2061 3532 2008 2026 2388 2109 2000 3198 2033 2000 2175 2175 2156 3611 12731 2480 2026 3611 2147 2012 1037 3806 2276 1998 2000 2175 2156 2032 2000 2156 2065 2002 2018 2769 2000 2022 2583 2000 4965 17153 28345 3022 2005 1996 2154 1998 2016 1045 3342 2008 2200 14954 2135 2009 2347 2102 2200 2521 12731 2480 1045 2123 2102 3342 2129 2521 2009 2165 2033 2000 2131 2045 2021 1045 2079 3342 2008 6230 1998 2026 3611 2001 2039 2200 10190 2057 2024 2200 10190 1998 2026 3611 2777 8307 2008 3047 2000 2022 1999 1996 2510 2008 2109 2000 2272 1999 2004 1037 7396 1998 2008 2711 2001 1996 2028 2008 2941 3271 2068 2707 1996 6653 2000 2131 2149 17352 2046 1996 2142 2163 2009 2001 2941 1037 7396 1997 1996 2326 2276 2008 2234 1999 2008 2330 1996 4303 1998 2057 2444 1999 1037 11825 3888 1996 11825 3888 2001 2028 1997 1996 2087 6919 6322 4921 2063 2412 2018 1999 2026 2166 2138 2000 2023 2154 2000 2023 2154 1045 2097 2175 2041 1997 2026 2126 1998 2016 2113 2073 2256 2436 2003 2012 2000 3298 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] pro ##no ##mbre ##s victoria fernandez ten ##go ci ##ent ##o se ##is an ##os the weather is los angeles historical norma co ##sm ##e you ##ll say norma fernandez ten ##go windy city an ##os au ##reus and doesn ##t appear better than those means yes yes i most analysts of the los angeles yes call me mama victoria fernandez gr ##ac ##ias mama por la pu ##lc ##ine ##lla mtv start a ke ##to ser ##est ##o phone tie ##mp ##o in a mosquito i said the broncos but the mint in them in a conversation somewhere to be the low low key master to cal ##ipe ##r look it up on there in nc ##t plus she seemed all their groin are planning to come over to be done to pueblo cu ##ales son tu ##s me ##jo ##res memorial si ##a read my ho ##ros ##cope memo ##rio ##us to spawn the way daniel cable cole ##gio bo ##scan mika ##sa 3 4 million we will need time and omar ##osa these the settlement emily to ##tem yank ##el super ##co ##pa much ##o por nos ##ot ##ros por el pri ##mos silver ##ado [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] pro ##no ##mbre ##s victoria fernandez ten ##go ci ##ent ##o se ##is an ##os the weather is los angeles historical norma co ##sm ##e you ##ll say norma fernandez ten ##go windy city an ##os au ##reus and doesn ##t appear better than those means yes yes i most analysts of the los angeles yes call me mama victoria fernandez gr ##ac ##ias mama por la pu ##lc ##ine ##lla mtv start a ke ##to ser ##est ##o phone tie ##mp ##o in a mosquito i said the broncos but the mint in them in a conversation somewhere to be the low low key master to cal ##ipe ##r look it up on there in nc ##t plus she seemed all their groin are planning to come over to be done to pueblo cu ##ales son tu ##s me ##jo ##res memorial si ##a read my ho ##ros ##cope memo ##rio ##us to spawn the way daniel cable cole ##gio bo ##scan mika ##sa 3 4 million we will need time and omar ##osa these the settlement emily to ##tem yank ##el super ##co ##pa much ##o por nos ##ot ##ros por el pri ##mos silver ##ado [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4013 3630 19908 2015 3848 12023 2702 3995 25022 4765 2080 7367 2483 2019 2891 1996 4633 2003 3050 3349 3439 20692 2522 6491 2063 2017 3363 2360 20692 12023 2702 3995 27370 2103 2019 2891 8740 23446 1998 2987 2102 3711 2488 2084 2216 2965 2748 2748 1045 2087 18288 1997 1996 3050 3349 2748 2655 2033 9588 3848 12023 24665 6305 7951 9588 18499 2474 16405 15472 3170 4571 8692 2707 1037 17710 3406 14262 4355 2080 3042 5495 8737 2080 1999 1037 22529 1045 2056 1996 14169 2021 1996 12927 1999 2068 1999 1037 4512 4873 2000 2022 1996 2659 2659 3145 3040 2000 10250 15457 2099 2298 2009 2039 2006 2045 1999 13316 2102 4606 2016 2790 2035 2037 20092 2024 4041 2000 2272 2058 2000 2022 2589 2000 18273 12731 23266 2365 10722 2015 2033 5558 6072 3986 9033 2050 3191 2026 7570 7352 16186 24443 9488 2271 2000 25645 1996 2126 3817 5830 5624 11411 8945 29378 27857 3736 1017 1018 2454 2057 2097 2342 2051 1998 13192 8820 2122 1996 4093 6253 2000 18532 23178 2884 3565 3597 4502 2172 2080 18499 16839 4140 7352 18499 3449 26927 15530 3165 9365 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4013 3630 19908 2015 3848 12023 2702 3995 25022 4765 2080 7367 2483 2019 2891 1996 4633 2003 3050 3349 3439 20692 2522 6491 2063 2017 3363 2360 20692 12023 2702 3995 27370 2103 2019 2891 8740 23446 1998 2987 2102 3711 2488 2084 2216 2965 2748 2748 1045 2087 18288 1997 1996 3050 3349 2748 2655 2033 9588 3848 12023 24665 6305 7951 9588 18499 2474 16405 15472 3170 4571 8692 2707 1037 17710 3406 14262 4355 2080 3042 5495 8737 2080 1999 1037 22529 1045 2056 1996 14169 2021 1996 12927 1999 2068 1999 1037 4512 4873 2000 2022 1996 2659 2659 3145 3040 2000 10250 15457 2099 2298 2009 2039 2006 2045 1999 13316 2102 4606 2016 2790 2035 2037 20092 2024 4041 2000 2272 2058 2000 2022 2589 2000 18273 12731 23266 2365 10722 2015 2033 5558 6072 3986 9033 2050 3191 2026 7570 7352 16186 24443 9488 2271 2000 25645 1996 2126 3817 5830 5624 11411 8945 29378 27857 3736 1017 1018 2454 2057 2097 2342 2051 1998 13192 8820 2122 1996 4093 6253 2000 18532 23178 2884 3565 3597 4502 2172 2080 18499 16839 4140 7352 18499 3449 26927 15530 3165 9365 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] look at your age latter ##ly he on the ne ##ph ##ron going to fight for the tournament tomorrow adi ##os mis abu ##eli ##tos es mi fa ##mi ##lia on the presence of pneumonia za ##les where is the staples el ar ##bol de la mis ##ma mu ##jer que limit ##a monica much ##amo ##re he has no cu ##ando tie ##nen los dia ##s de na ##vid ##ad para nos ##ot ##ros so ##mos de tod ##os ce ##le ##bra ##mos la mesa mesa arizona receive para ##iso with japan the loss of your state high school and high school students put on hello kitty music black glasses where to go sis ##ta cab ##all ##os del campo the first time i saw him we wanted toys police okay your ##e on the volume a mi gust ##a much ##o me si ##ent ##o mu ##y fe ##li ##z me si ##ent ##o fe ##li ##z madonna on polo ic ##mp p m see i guess hit me up when you talk unless es ##pan ##ol para para car ##gar co ##sas en la part ##e kathy to ##cco mata los poll ##os lafayette this [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] look at your age latter ##ly he on the ne ##ph ##ron going to fight for the tournament tomorrow adi ##os mis abu ##eli ##tos es mi fa ##mi ##lia on the presence of pneumonia za ##les where is the staples el ar ##bol de la mis ##ma mu ##jer que limit ##a monica much ##amo ##re he has no cu ##ando tie ##nen los dia ##s de na ##vid ##ad para nos ##ot ##ros so ##mos de tod ##os ce ##le ##bra ##mos la mesa mesa arizona receive para ##iso with japan the loss of your state high school and high school students put on hello kitty music black glasses where to go sis ##ta cab ##all ##os del campo the first time i saw him we wanted toys police okay your ##e on the volume a mi gust ##a much ##o me si ##ent ##o mu ##y fe ##li ##z me si ##ent ##o fe ##li ##z madonna on polo ic ##mp p m see i guess hit me up when you talk unless es ##pan ##ol para para car ##gar co ##sas en la part ##e kathy to ##cco mata los poll ##os lafayette this [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2298 2012 2115 2287 3732 2135 2002 2006 1996 11265 8458 4948 2183 2000 2954 2005 1996 2977 4826 27133 2891 28616 8273 20806 13122 9686 2771 6904 4328 6632 2006 1996 3739 1997 18583 23564 4244 2073 2003 1996 24533 3449 12098 14956 2139 2474 28616 2863 14163 20009 10861 5787 2050 9018 2172 22591 2890 2002 2038 2053 12731 28574 5495 10224 3050 22939 2015 2139 6583 17258 4215 11498 16839 4140 7352 2061 15530 2139 28681 2891 8292 2571 10024 15530 2474 15797 15797 5334 4374 11498 19565 2007 2900 1996 3279 1997 2115 2110 2152 2082 1998 2152 2082 2493 2404 2006 7592 14433 2189 2304 7877 2073 2000 2175 24761 2696 9298 8095 2891 3972 22339 1996 2034 2051 1045 2387 2032 2057 2359 10899 2610 3100 2115 2063 2006 1996 3872 1037 2771 26903 2050 2172 2080 2033 9033 4765 2080 14163 2100 10768 3669 2480 2033 9033 4765 2080 10768 3669 2480 11284 2006 11037 24582 8737 1052 1049 2156 1045 3984 2718 2033 2039 2043 2017 2831 4983 9686 9739 4747 11498 11498 2482 6843 2522 20939 4372 2474 2112 2063 14986 2000 21408 22640 3050 8554 2891 14425 2023 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2298 2012 2115 2287 3732 2135 2002 2006 1996 11265 8458 4948 2183 2000 2954 2005 1996 2977 4826 27133 2891 28616 8273 20806 13122 9686 2771 6904 4328 6632 2006 1996 3739 1997 18583 23564 4244 2073 2003 1996 24533 3449 12098 14956 2139 2474 28616 2863 14163 20009 10861 5787 2050 9018 2172 22591 2890 2002 2038 2053 12731 28574 5495 10224 3050 22939 2015 2139 6583 17258 4215 11498 16839 4140 7352 2061 15530 2139 28681 2891 8292 2571 10024 15530 2474 15797 15797 5334 4374 11498 19565 2007 2900 1996 3279 1997 2115 2110 2152 2082 1998 2152 2082 2493 2404 2006 7592 14433 2189 2304 7877 2073 2000 2175 24761 2696 9298 8095 2891 3972 22339 1996 2034 2051 1045 2387 2032 2057 2359 10899 2610 3100 2115 2063 2006 1996 3872 1037 2771 26903 2050 2172 2080 2033 9033 4765 2080 14163 2100 10768 3669 2480 2033 9033 4765 2080 10768 3669 2480 11284 2006 11037 24582 8737 1052 1049 2156 1045 3984 2718 2033 2039 2043 2017 2831 4983 9686 9739 4747 11498 11498 2482 6843 2522 20939 4372 2474 2112 2063 14986 2000 21408 22640 3050 8554 2891 14425 2023 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] at el poll ##o come on okay we will need nes to english he was there to conduct a custom message to kit ##a ku monica never attended billy sq ##ui ##er mi gust ##a by much ##o como the memorial spoken can ##no ##lis yes get the memo ##ji side rental ##s hasty made a vehicle matthias he ##iman ##so ##hn ll ##oro ##na rec ##eta ##s but im going to send you a quote mai ##sel a mo ##jit ##o olympia painter start this year he ##pati ##ca mi ##mos ##a me sol ##ito ##s cu ##ales fu ##eron su ##s no ##mbre ##s cu ##anto ##s an ##os est ##u ##vo en ing ##les como se como se con ##oc ##ier ##on do you spell pas ##a cu ##ando ci ##er ##ran maybe i know i know you hate yourself los cr ##ister ##os but yo cr ##eo el go ##bie ##rno que est ##aba en contra de la religion i don ##t think its going to be an angel sister a birthday korean as ##ient ##os bautista ##s en las casa ##s de los mat ##rim ##oni ##os tam ##bie ##n es ##con ##di [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] at el poll ##o come on okay we will need nes to english he was there to conduct a custom message to kit ##a ku monica never attended billy sq ##ui ##er mi gust ##a by much ##o como the memorial spoken can ##no ##lis yes get the memo ##ji side rental ##s hasty made a vehicle matthias he ##iman ##so ##hn ll ##oro ##na rec ##eta ##s but im going to send you a quote mai ##sel a mo ##jit ##o olympia painter start this year he ##pati ##ca mi ##mos ##a me sol ##ito ##s cu ##ales fu ##eron su ##s no ##mbre ##s cu ##anto ##s an ##os est ##u ##vo en ing ##les como se como se con ##oc ##ier ##on do you spell pas ##a cu ##ando ci ##er ##ran maybe i know i know you hate yourself los cr ##ister ##os but yo cr ##eo el go ##bie ##rno que est ##aba en contra de la religion i don ##t think its going to be an angel sister a birthday korean as ##ient ##os bautista ##s en las casa ##s de los mat ##rim ##oni ##os tam ##bie ##n es ##con ##di [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2012 3449 8554 2080 2272 2006 3100 2057 2097 2342 24524 2000 2394 2002 2001 2045 2000 6204 1037 7661 4471 2000 8934 2050 13970 9018 2196 3230 5006 5490 10179 2121 2771 26903 2050 2011 2172 2080 18609 1996 3986 5287 2064 3630 6856 2748 2131 1996 24443 4478 2217 12635 2015 27151 2081 1037 4316 17885 2002 18505 6499 7295 2222 14604 2532 28667 12928 2015 2021 10047 2183 2000 4604 2017 1037 14686 14736 11246 1037 9587 18902 2080 17096 5276 2707 2023 2095 2002 24952 3540 2771 15530 2050 2033 14017 9956 2015 12731 23266 11865 26534 10514 2015 2053 19908 2015 12731 21634 2015 2019 2891 9765 2226 6767 4372 13749 4244 18609 7367 18609 7367 9530 10085 3771 2239 2079 2017 6297 14674 2050 12731 28574 25022 2121 5521 2672 1045 2113 1045 2113 2017 5223 4426 3050 13675 12911 2891 2021 10930 13675 8780 3449 2175 11283 19139 10861 9765 19736 4372 24528 2139 2474 4676 1045 2123 2102 2228 2049 2183 2000 2022 2019 4850 2905 1037 5798 4759 2004 11638 2891 27845 2015 4372 5869 14124 2015 2139 3050 13523 20026 10698 2891 17214 11283 2078 9686 8663 4305 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2012 3449 8554 2080 2272 2006 3100 2057 2097 2342 24524 2000 2394 2002 2001 2045 2000 6204 1037 7661 4471 2000 8934 2050 13970 9018 2196 3230 5006 5490 10179 2121 2771 26903 2050 2011 2172 2080 18609 1996 3986 5287 2064 3630 6856 2748 2131 1996 24443 4478 2217 12635 2015 27151 2081 1037 4316 17885 2002 18505 6499 7295 2222 14604 2532 28667 12928 2015 2021 10047 2183 2000 4604 2017 1037 14686 14736 11246 1037 9587 18902 2080 17096 5276 2707 2023 2095 2002 24952 3540 2771 15530 2050 2033 14017 9956 2015 12731 23266 11865 26534 10514 2015 2053 19908 2015 12731 21634 2015 2019 2891 9765 2226 6767 4372 13749 4244 18609 7367 18609 7367 9530 10085 3771 2239 2079 2017 6297 14674 2050 12731 28574 25022 2121 5521 2672 1045 2113 1045 2113 2017 5223 4426 3050 13675 12911 2891 2021 10930 13675 8780 3449 2175 11283 19139 10861 9765 19736 4372 24528 2139 2474 4676 1045 2123 2102 2228 2049 2183 2000 2022 2019 4850 2905 1037 5798 4759 2004 11638 2891 27845 2015 4372 5869 14124 2015 2139 3050 13523 20026 10698 2891 17214 11283 2078 9686 8663 4305 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] safe and jose casa ##do because i don ##t even mat ##rim ##onia ##l boys we will need other quality tango rec ##uer ##do mat ##rim ##onia ##l e ##je ##mp ##los por ##que yo nun ##ca nun ##ca se pe ##lean wander ##mere my name alice lester call dos an ##os de casa ##dos por que ho ##ras del dia prime ##ro de en ##ero de dos mil si ##ete im ##me ##mori ##al don ##t say the narrow is the seal but i think that ##s what im going to say hello to include a headache we must got our sob ##rer ##o be ##be ##mos the assembly room qu ##att ##ro chi ##qui ##to de ser una casa de pu ##ras mu ##jer ##es de ba ##jo in tor ##to ##la im hard to be to see a joke about my uncle is can ##cion ##es del rec ##uer ##do so that was kind of my sob ##re primera can ##cion de des ##pie ##rta rig ##o is got ##cha i mod ##i india maria elena you economist ##a a mexico ja ##lis ##co kit guess well get there with us attack on the bus [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] safe and jose casa ##do because i don ##t even mat ##rim ##onia ##l boys we will need other quality tango rec ##uer ##do mat ##rim ##onia ##l e ##je ##mp ##los por ##que yo nun ##ca nun ##ca se pe ##lean wander ##mere my name alice lester call dos an ##os de casa ##dos por que ho ##ras del dia prime ##ro de en ##ero de dos mil si ##ete im ##me ##mori ##al don ##t say the narrow is the seal but i think that ##s what im going to say hello to include a headache we must got our sob ##rer ##o be ##be ##mos the assembly room qu ##att ##ro chi ##qui ##to de ser una casa de pu ##ras mu ##jer ##es de ba ##jo in tor ##to ##la im hard to be to see a joke about my uncle is can ##cion ##es del rec ##uer ##do so that was kind of my sob ##re primera can ##cion de des ##pie ##rta rig ##o is got ##cha i mod ##i india maria elena you economist ##a a mexico ja ##lis ##co kit guess well get there with us attack on the bus [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3647 1998 4560 14124 3527 2138 1045 2123 2102 2130 13523 20026 12488 2140 3337 2057 2097 2342 2060 3737 17609 28667 13094 3527 13523 20026 12488 2140 1041 6460 8737 10483 18499 4226 10930 16634 3540 16634 3540 7367 21877 20898 17677 13759 2026 2171 5650 14131 2655 9998 2019 2891 2139 14124 12269 18499 10861 7570 8180 3972 22939 3539 3217 2139 4372 10624 2139 9998 23689 9033 12870 10047 4168 24610 2389 2123 2102 2360 1996 4867 2003 1996 7744 2021 1045 2228 2008 2015 2054 10047 2183 2000 2360 7592 2000 2421 1037 14978 2057 2442 2288 2256 17540 14544 2080 2022 4783 15530 1996 3320 2282 24209 19321 3217 9610 15549 3406 2139 14262 14477 14124 2139 16405 8180 14163 20009 2229 2139 8670 5558 1999 17153 3406 2721 10047 2524 2000 2022 2000 2156 1037 8257 2055 2026 4470 2003 2064 10446 2229 3972 28667 13094 3527 2061 2008 2001 2785 1997 2026 17540 2890 14837 2064 10446 2139 4078 14756 13320 19838 2080 2003 2288 7507 1045 16913 2072 2634 3814 9060 2017 11708 2050 1037 3290 14855 6856 3597 8934 3984 2092 2131 2045 2007 2149 2886 2006 1996 3902 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3647 1998 4560 14124 3527 2138 1045 2123 2102 2130 13523 20026 12488 2140 3337 2057 2097 2342 2060 3737 17609 28667 13094 3527 13523 20026 12488 2140 1041 6460 8737 10483 18499 4226 10930 16634 3540 16634 3540 7367 21877 20898 17677 13759 2026 2171 5650 14131 2655 9998 2019 2891 2139 14124 12269 18499 10861 7570 8180 3972 22939 3539 3217 2139 4372 10624 2139 9998 23689 9033 12870 10047 4168 24610 2389 2123 2102 2360 1996 4867 2003 1996 7744 2021 1045 2228 2008 2015 2054 10047 2183 2000 2360 7592 2000 2421 1037 14978 2057 2442 2288 2256 17540 14544 2080 2022 4783 15530 1996 3320 2282 24209 19321 3217 9610 15549 3406 2139 14262 14477 14124 2139 16405 8180 14163 20009 2229 2139 8670 5558 1999 17153 3406 2721 10047 2524 2000 2022 2000 2156 1037 8257 2055 2026 4470 2003 2064 10446 2229 3972 28667 13094 3527 2061 2008 2001 2785 1997 2026 17540 2890 14837 2064 10446 2139 4078 14756 13320 19838 2080 2003 2288 7507 1045 16913 2072 2634 3814 9060 2017 11708 2050 1037 3290 14855 6856 3597 8934 3984 2092 2131 2045 2007 2149 2886 2006 1996 3902 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] staff we must we must we must have a tom ##ar f ##oto ##s de jar ##din anita pad ##illa okay ill just get up at super one that ##s over there to experience e a ##qui en los est ##ados un ##ido ##s se como se quit ##a mal ##dic ##ion ep ##ista ##tic americana condom ##inium ##s des por que va ##mos de sept ##ie ##mbre the meaning of a ci ##ent ##o set ##ent ##a uganda famous el consul ##ado bedroom house for sale in plaza de si ##ete me ##ses no pas ##a por ##que en ##ton ##ces por ci ##ent ##o se ##is de ab ##ri ##gos de una fabric ##a de cost ##o de una ga ##rra ##pa ##ta was delaware avenue monte ##sso ##ri in town san diego and they stay rihanna disneyland ##ia is better than ending alan ##dia good morning got to roll home and send you away i just gotta see if i don ##t know what ##s going on near marina del rey de la sen ##ora little joe and the dollar is bang ##o bon ##go in a separate area he persisted mean elizabeth until your [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] staff we must we must we must have a tom ##ar f ##oto ##s de jar ##din anita pad ##illa okay ill just get up at super one that ##s over there to experience e a ##qui en los est ##ados un ##ido ##s se como se quit ##a mal ##dic ##ion ep ##ista ##tic americana condom ##inium ##s des por que va ##mos de sept ##ie ##mbre the meaning of a ci ##ent ##o set ##ent ##a uganda famous el consul ##ado bedroom house for sale in plaza de si ##ete me ##ses no pas ##a por ##que en ##ton ##ces por ci ##ent ##o se ##is de ab ##ri ##gos de una fabric ##a de cost ##o de una ga ##rra ##pa ##ta was delaware avenue monte ##sso ##ri in town san diego and they stay rihanna disneyland ##ia is better than ending alan ##dia good morning got to roll home and send you away i just gotta see if i don ##t know what ##s going on near marina del rey de la sen ##ora little joe and the dollar is bang ##o bon ##go in a separate area he persisted mean elizabeth until your [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3095 2057 2442 2057 2442 2057 2442 2031 1037 3419 2906 1042 11439 2015 2139 15723 8718 12918 11687 9386 3100 5665 2074 2131 2039 2012 3565 2028 2008 2015 2058 2045 2000 3325 1041 1037 15549 4372 3050 9765 28118 4895 13820 2015 7367 18609 7367 8046 2050 15451 14808 3258 4958 11921 4588 25988 20910 27585 2015 4078 18499 10861 12436 15530 2139 17419 2666 19908 1996 3574 1997 1037 25022 4765 2080 2275 4765 2050 10031 3297 3449 11801 9365 5010 2160 2005 5096 1999 8232 2139 9033 12870 2033 8583 2053 14674 2050 18499 4226 4372 2669 9623 18499 25022 4765 2080 7367 2483 2139 11113 3089 12333 2139 14477 8313 2050 2139 3465 2080 2139 14477 11721 11335 4502 2696 2001 8452 3927 10125 24137 3089 1999 2237 2624 5277 1998 2027 2994 25439 25104 2401 2003 2488 2084 4566 5070 9032 2204 2851 2288 2000 4897 2188 1998 4604 2017 2185 1045 2074 10657 2156 2065 1045 2123 2102 2113 2054 2015 2183 2006 2379 9985 3972 12569 2139 2474 12411 6525 2210 3533 1998 1996 7922 2003 9748 2080 14753 3995 1999 1037 3584 2181 2002 19035 2812 3870 2127 2115 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3095 2057 2442 2057 2442 2057 2442 2031 1037 3419 2906 1042 11439 2015 2139 15723 8718 12918 11687 9386 3100 5665 2074 2131 2039 2012 3565 2028 2008 2015 2058 2045 2000 3325 1041 1037 15549 4372 3050 9765 28118 4895 13820 2015 7367 18609 7367 8046 2050 15451 14808 3258 4958 11921 4588 25988 20910 27585 2015 4078 18499 10861 12436 15530 2139 17419 2666 19908 1996 3574 1997 1037 25022 4765 2080 2275 4765 2050 10031 3297 3449 11801 9365 5010 2160 2005 5096 1999 8232 2139 9033 12870 2033 8583 2053 14674 2050 18499 4226 4372 2669 9623 18499 25022 4765 2080 7367 2483 2139 11113 3089 12333 2139 14477 8313 2050 2139 3465 2080 2139 14477 11721 11335 4502 2696 2001 8452 3927 10125 24137 3089 1999 2237 2624 5277 1998 2027 2994 25439 25104 2401 2003 2488 2084 4566 5070 9032 2204 2851 2288 2000 4897 2188 1998 4604 2017 2185 1045 2074 10657 2156 2065 1045 2123 2102 2113 2054 2015 2183 2006 2379 9985 3972 12569 2139 2474 12411 6525 2210 3533 1998 1996 7922 2003 9748 2080 14753 3995 1999 1037 3584 2181 2002 19035 2812 3870 2127 2115 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    }
   ],
   "source": [
    "# Convert our train and validation features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \n",
    "  bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "  # Use \"sequence_outputs\" for token-level output.\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "  # with tf.Session() as sess:\n",
    "  output_layer1 = bert_outputs[\"pooled_output\"]\n",
    "  # output_layer1 = 999\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  # Create our own layer to tune for politeness data.\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.8)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs, output_layer1)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        true_pos = tf.metrics.true_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        true_neg = tf.metrics.true_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)   \n",
    "        false_pos = tf.metrics.false_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)  \n",
    "        false_neg = tf.metrics.false_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        \n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            \"true_positives\": true_pos,\n",
    "            \"true_negatives\": true_neg,\n",
    "            \"false_positives\": false_pos,\n",
    "            \"false_negatives\": false_neg,\n",
    "            }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs, output_layer) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels,\n",
    "          'pooled_output': output_layer\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1.0\n",
    "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 300\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "# Compute train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(982, 5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_steps, len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './bert_output/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002D3DE83B9E8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './bert_output/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002D3DE83B9E8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "#Initializing the model and the estimator\n",
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)\n",
    "\n",
    "# Create an input function for validating. drop_remainder = True for using TPUs.\n",
    "val_input_fn = run_classifier.input_fn_builder(\n",
    "    features=val_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n",
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-42-a75d089b65af>:35: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-42-a75d089b65af>:35: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.5512984, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.5512984, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.80541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.80541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04328139, step = 100 (35.646 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.04328139, step = 100 (35.646 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.74017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.74017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.004184951, step = 200 (26.738 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.004184951, step = 200 (26.738 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 300 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 300 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.3632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.3632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.5355225, step = 300 (42.315 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.5355225, step = 300 (42.315 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.71035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.71035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.9976492, step = 400 (26.951 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.9976492, step = 400 (26.951 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.81222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.81222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.9562984, step = 500 (26.231 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.9562984, step = 500 (26.231 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 600 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 600 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.36194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.36194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.536268, step = 600 (42.339 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.536268, step = 600 (42.339 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.81149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.81149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.708729, step = 700 (26.235 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.708729, step = 700 (26.235 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.8109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.8109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.024514882, step = 800 (26.242 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.024514882, step = 800 (26.242 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 900 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 900 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.38906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.38906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.6893954, step = 900 (41.856 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.6893954, step = 900 (41.856 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 982 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 982 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.54935765.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.54935765.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took time  0:07:05.176723\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-09-21T04:11:33Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-09-21T04:11:33Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./bert_output/model.ckpt-982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./bert_output/model.ckpt-982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-09-21-04:11:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-09-21-04:11:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 982: eval_accuracy = 0.8027383, false_negatives = 0.0, false_positives = 26.0, global_step = 982, loss = 0.9358122, true_negatives = 0.0, true_positives = 1946.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 982: eval_accuracy = 0.8027383, false_negatives = 0.0, false_positives = 26.0, global_step = 982, loss = 0.9358122, true_negatives = 0.0, true_positives = 1946.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 982: ./bert_output/model.ckpt-982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 982: ./bert_output/model.ckpt-982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.8027383,\n",
       " 'false_negatives': 0.0,\n",
       " 'false_positives': 26.0,\n",
       " 'loss': 0.9358122,\n",
       " 'true_negatives': 0.0,\n",
       " 'true_positives': 1946.0,\n",
       " 'global_step': 982}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the model with Validation set\n",
    "estimator.evaluate(input_fn=val_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A method to get predictions\n",
    "def getPrediction(in_sentences, type_output = \"features\"):\n",
    "  #A list to map the actual labels to the predictions\n",
    "  labels = np.unique(train['label'])\n",
    "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n",
    "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  #Predicting the classes \n",
    "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "  predictions = estimator.predict(predict_input_fn)\n",
    "  if type_output == \"features\":\n",
    "    return [prediction['pooled_output'] for _,prediction in enumerate(predictions) ]\n",
    "  else:\n",
    "    return ([(sentence, prediction['probabilities'],\n",
    "              prediction['labels'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.logging.ERROR)\n",
    "MAX_SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7859, 2), (1972, 2))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my name is Cindy Mosqueda Im 29 years old toda...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was born in your parents my parents are or w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and my mother was living in town so they met b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>go do you want most of this is what Ive been t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>me we were so so poor that my mother used to a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  my name is Cindy Mosqueda Im 29 years old toda...      3\n",
       "1  I was born in your parents my parents are or w...      3\n",
       "2  and my mother was living in town so they met b...      3\n",
       "3  go do you want most of this is what Ive been t...      3\n",
       "4  me we were so so poor that my mother used to a...      3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transcript_raw = transcript_raw[transcript_raw.human_transcript.notnull()]\n",
    "# train_df = train_df[train_df.DATA_COLUMN.notnull()]\n",
    "# train_df.shape\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tr_emb = np.apply_along_axis(getPrediction, 0,np.array(train_df[DATA_COLUMN]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1972, 768)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "val_emb = np.apply_along_axis(getPrediction, 0,np.array(val_df[DATA_COLUMN]))\n",
    "val_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1972, 768), (7859, 768))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_emb.shape, tr_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = -1\n",
    "len_l = 0\n",
    "train_x = {}\n",
    "for l, emb in zip(index_l, tr_emb):\n",
    "  if l in train_x.keys():\n",
    "    train_x[l]  =np.vstack([train_x[l], emb])\n",
    "  else:\n",
    "    train_x[l] = [emb]\n",
    "\n",
    "len(train_x.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.9794256, -0.59988445, 0.9161703, 0.347102...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-0.9794501, -0.6005068, 0.9161681, 0.3469362...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.9792903, -0.6004153, 0.91549295, 0.348133...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.9792723, -0.6000406, 0.9154477, 0.346477,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.9791686, -0.59854317, 0.91483086, 0.34641...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emb  label\n",
       "0  [[-0.9794256, -0.59988445, 0.9161703, 0.347102...      3\n",
       "1  [[-0.9794501, -0.6005068, 0.9161681, 0.3469362...      3\n",
       "2  [[-0.9792903, -0.6004153, 0.91549295, 0.348133...      3\n",
       "3  [[-0.9792723, -0.6000406, 0.9154477, 0.346477,...      3\n",
       "4  [[-0.9791686, -0.59854317, 0.91483086, 0.34641...      4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_l_final = []\n",
    "label_l_final = []\n",
    "for k in train_x.keys():\n",
    "  train_l_final.append(train_x[k])\n",
    "  label_l_final.append(train.loc[k]['label'])\n",
    "\n",
    "df_train = pd.DataFrame({'emb': train_l_final, 'label': label_l_final, })\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.9779639, -0.59722364, 0.9129541, 0.334442...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-0.9794135, -0.60033906, 0.91595435, 0.34620...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.9780164, -0.5954613, 0.9131257, 0.3403696...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.9795296, -0.60106283, 0.9158731, 0.347619...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.97945964, -0.6002956, 0.9162129, 0.347096...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emb  label\n",
       "0  [[-0.9779639, -0.59722364, 0.9129541, 0.334442...      3\n",
       "1  [[-0.9794135, -0.60033906, 0.91595435, 0.34620...      3\n",
       "2  [[-0.9780164, -0.5954613, 0.9131257, 0.3403696...      3\n",
       "3  [[-0.9795296, -0.60106283, 0.9158731, 0.347619...      4\n",
       "4  [[-0.97945964, -0.6002956, 0.9162129, 0.347096...      3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = -1\n",
    "len_l = 0\n",
    "val_x = {}\n",
    "\n",
    "for l, emb in zip(val_index_l, val_emb):\n",
    "  if l in val_x.keys():\n",
    "    val_x[l]  =np.vstack([val_x[l], emb])\n",
    "  else:\n",
    "    val_x[l] = [emb]\n",
    "\n",
    "\n",
    "val_l_final = []\n",
    "vlabel_l_final = []\n",
    "for k in val_x.keys():\n",
    "  val_l_final.append(val_x[k])\n",
    "  vlabel_l_final.append(val.loc[k]['label'])\n",
    "\n",
    "df_val = pd.DataFrame({'emb': val_l_final, 'label': vlabel_l_final})\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val, df_test = train_test_split(df_val, test_size=0.4, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text (InputLayer)            (None, None, 768)         0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, None, 768)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               347600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 155       \n",
      "=================================================================\n",
      "Total params: 350,785\n",
      "Trainable params: 350,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "text_input = Input(shape=(None,768,), dtype='float32', name='text')\n",
    "\n",
    "l_mask = layers.Masking(mask_value=-99.)(text_input)\n",
    "# Which we encoded in a single vector via a LSTM\n",
    "encoded_text = layers.LSTM(100,)(l_mask)\n",
    "out_dense = layers.Dense(30, activation='relu')(encoded_text)\n",
    "# And we add a softmax classifier on top\n",
    "out = layers.Dense(len(label_list), activation='softmax')(out_dense)\n",
    "# At model instantiation, we specify the input and the output:\n",
    "model = Model(text_input, out)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((265, 2), (40, 2), (27, 2))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sequences = len(df_train['emb'].to_list())\n",
    "num_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences = len(df_train['emb'].to_list())\n",
    "batch_size = 5\n",
    "batches_per_epoch =  53\n",
    "assert batch_size * batches_per_epoch == num_sequences\n",
    "num_features= 768\n",
    "def train_generator(df):\n",
    "    x_list= df['emb'].to_list()\n",
    "    y_list =  df.label.to_list()\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch):\n",
    "            longest_index = (b + 1) * batch_size - 1\n",
    "            timesteps = len(max(df['emb'].to_list()[:(b + 1) * batch_size][-batch_size:], key=len))\n",
    "            x_train = np.full((batch_size, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size,  1))\n",
    "            for i in range(batch_size):\n",
    "                li = b * batch_size + i\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sequences_val = len(df_val['emb'].to_list())\n",
    "num_sequences_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences_val = len(df_val['emb'].to_list())\n",
    "batch_size_val = 4\n",
    "batches_per_epoch_val = 10\n",
    "assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
    "num_features= 768\n",
    "def val_generator(df):\n",
    "    x_list= df['emb'].to_list()\n",
    "    y_list =  df.label.to_list()\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch_val):\n",
    "            longest_index = (b + 1) * batch_size_val - 1\n",
    "            timesteps = len(max(df['emb'].to_list()[:(b + 1) * batch_size_val][-31:], key=len))\n",
    "            # print(len(df_train['emb'].to_list()[:b+batch_size][-7:]))\n",
    "            x_train = np.full((batch_size_val, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size_val,  1))\n",
    "            for i in range(batch_size_val):\n",
    "                li = b * batch_size_val + i\n",
    "                # print(\"li\", li)\n",
    "                # print(x_train[i, 0:len(x_list[li]), :].shape, len(x_list[li]))\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "call_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.95, patience=3, verbose=2,\n",
    "                                mode='auto', min_delta=0.01, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.6136 - acc: 0.8453 - val_loss: 1.0609 - val_acc: 0.7750\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.5387 - acc: 0.8604 - val_loss: 1.0793 - val_acc: 0.7750\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.5327 - acc: 0.8604 - val_loss: 1.0913 - val_acc: 0.7750\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.5315 - acc: 0.8604 - val_loss: 1.0958 - val_acc: 0.7750\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.5312 - acc: 0.8604 - val_loss: 1.0831 - val_acc: 0.7750\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.5299 - acc: 0.8604 - val_loss: 1.0918 - val_acc: 0.7750\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.5295 - acc: 0.8604 - val_loss: 1.0951 - val_acc: 0.7750\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.5290 - acc: 0.8604 - val_loss: 1.0984 - val_acc: 0.7750\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.5290 - acc: 0.8604 - val_loss: 1.0994 - val_acc: 0.7750\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.5289 - acc: 0.8604 - val_loss: 1.1010 - val_acc: 0.7750\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2d3b4550358>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator(df_train), steps_per_epoch=batches_per_epoch, epochs=10,\n",
    "                    validation_data=val_generator(df_val), validation_steps=batches_per_epoch_val, callbacks =[call_reduce] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sequences_val = len(df_test['emb'].to_list())\n",
    "num_sequences_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14934326708316803, 0.8518518805503845]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sequences_val = len(df_test['emb'].to_list())\n",
    "batch_size_val = 3\n",
    "batches_per_epoch_val = 9\n",
    "assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
    "num_features= 768\n",
    "model.evaluate_generator(val_generator(df_test), steps= batches_per_epoch_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
