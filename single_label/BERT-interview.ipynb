{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 1.x\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "from keras import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import LSTM, Dense, Masking\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Dense, Input, concatenate, Layer, Lambda, Dropout, Activation\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, TensorBoard\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'label3-g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unnamed:_0</th>\n",
       "      <th>interview_id</th>\n",
       "      <th>interview_date</th>\n",
       "      <th>record_creation_date</th>\n",
       "      <th>venue</th>\n",
       "      <th>address_name</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state_/_province</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>...</th>\n",
       "      <th>interviewer_relationship_5_to_storyteller_2</th>\n",
       "      <th>language_1</th>\n",
       "      <th>language_2</th>\n",
       "      <th>language_3</th>\n",
       "      <th>keywords_-_fixed_subjects</th>\n",
       "      <th>keywords_-_general</th>\n",
       "      <th>keywords_-_places</th>\n",
       "      <th>deep_speech</th>\n",
       "      <th>human_transcript</th>\n",
       "      <th>google_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MBY005668</td>\n",
       "      <td>9/5/09 11:30</td>\n",
       "      <td>9/5/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Achievements and Awards\\n\\nChildren\\n\\nCommuni...</td>\n",
       "      <td>bilingual\\n\\nBilingue\\n\\nChihuahua, Mexico\\n\\n...</td>\n",
       "      <td></td>\n",
       "      <td>i am an amadis so my lawyer in whitewashin or ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I mean I'm already so my lawyer Singapore and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MBY005704</td>\n",
       "      <td>9/12/09 14:30</td>\n",
       "      <td>9/12/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Childcare\\n\\nChildren\\n\\nTraumatic Memories</td>\n",
       "      <td>accidents\\n\\nbilingual\\n\\nbirth of first child...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all me i olliphant elocution cutaneous or a sa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>call mi amor Alejandro De La Cruz Munoz arrest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MBY005712</td>\n",
       "      <td>9/13/09 17:30</td>\n",
       "      <td>9/13/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anniversaries\\n\\nChildren\\n\\nCommunity Busines...</td>\n",
       "      <td>accidents\\n\\nbaile\\n\\ncar accident\\n\\ncemetery...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it kanonsionni neesnetasis officiousness miste...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>okay mean Hombres es el Amante Samira cincuent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MBY005713</td>\n",
       "      <td>9/14/09 9:30</td>\n",
       "      <td>9/14/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Birth\\n\\nBurials\\n\\nCancer\\n\\nChildcare\\n\\nChi...</td>\n",
       "      <td>alcohol\\n\\nbirth of first child\\n\\nchemotherap...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my name is maria humphry i'm twenty six to day...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my name is Melissa Humphrey I'm 26 today's dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MBY005730</td>\n",
       "      <td>9/18/09 12:30</td>\n",
       "      <td>9/18/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Changes In Education\\n\\nCommunity Businesses\\n...</td>\n",
       "      <td>anecdotes (humorous but true stories)\\n\\nappea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the woman silence hello my name is alan fucara...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hello my name is Adolfo Carranza Junior and I'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unnamed:_0 interview_id interview_date record_creation_date  \\\n",
       "0           0    MBY005668   9/5/09 11:30               9/5/09   \n",
       "1           1    MBY005704  9/12/09 14:30              9/12/09   \n",
       "2           2    MBY005712  9/13/09 17:30              9/13/09   \n",
       "3           3    MBY005713   9/14/09 9:30              9/14/09   \n",
       "4           4    MBY005730  9/18/09 12:30              9/18/09   \n",
       "\n",
       "                    venue      address_name                 street    city  \\\n",
       "0  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library  Paonia   \n",
       "1  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library  Paonia   \n",
       "2  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library  Paonia   \n",
       "3  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library  Paonia   \n",
       "4  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library  Paonia   \n",
       "\n",
       "  state_/_province  postal_code  ...  \\\n",
       "0               CO      81428.0  ...   \n",
       "1               CO      81428.0  ...   \n",
       "2               CO      81428.0  ...   \n",
       "3               CO      81428.0  ...   \n",
       "4               CO      81428.0  ...   \n",
       "\n",
       "  interviewer_relationship_5_to_storyteller_2 language_1 language_2  \\\n",
       "0                                         NaN    Spanish        NaN   \n",
       "1                                         NaN    Spanish        NaN   \n",
       "2                                         NaN    Spanish        NaN   \n",
       "3                                         NaN    English        NaN   \n",
       "4                                         NaN        NaN        NaN   \n",
       "\n",
       "  language_3                          keywords_-_fixed_subjects  \\\n",
       "0        NaN  Achievements and Awards\\n\\nChildren\\n\\nCommuni...   \n",
       "1        NaN        Childcare\\n\\nChildren\\n\\nTraumatic Memories   \n",
       "2        NaN  Anniversaries\\n\\nChildren\\n\\nCommunity Busines...   \n",
       "3        NaN  Birth\\n\\nBurials\\n\\nCancer\\n\\nChildcare\\n\\nChi...   \n",
       "4        NaN  Changes In Education\\n\\nCommunity Businesses\\n...   \n",
       "\n",
       "                                  keywords_-_general keywords_-_places  \\\n",
       "0  bilingual\\n\\nBilingue\\n\\nChihuahua, Mexico\\n\\n...                     \n",
       "1  accidents\\n\\nbilingual\\n\\nbirth of first child...               NaN   \n",
       "2  accidents\\n\\nbaile\\n\\ncar accident\\n\\ncemetery...               NaN   \n",
       "3  alcohol\\n\\nbirth of first child\\n\\nchemotherap...               NaN   \n",
       "4  anecdotes (humorous but true stories)\\n\\nappea...               NaN   \n",
       "\n",
       "                                         deep_speech  human_transcript  \\\n",
       "0  i am an amadis so my lawyer in whitewashin or ...               NaN   \n",
       "1  all me i olliphant elocution cutaneous or a sa...               NaN   \n",
       "2  it kanonsionni neesnetasis officiousness miste...               NaN   \n",
       "3  my name is maria humphry i'm twenty six to day...               NaN   \n",
       "4  the woman silence hello my name is alan fucara...               NaN   \n",
       "\n",
       "                                   google_transcript  \n",
       "0  I mean I'm already so my lawyer Singapore and ...  \n",
       "1  call mi amor Alejandro De La Cruz Munoz arrest...  \n",
       "2  okay mean Hombres es el Amante Samira cincuent...  \n",
       "3  my name is Melissa Humphrey I'm 26 today's dat...  \n",
       "4  hello my name is Adolfo Carranza Junior and I'...  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_raw = pd.read_csv('Data/transcript.csv')\n",
    "transcript_raw.columns = transcript_raw.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "transcript_raw = transcript_raw[transcript_raw.google_transcript.notnull()]\n",
    "transcript_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349, 61)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interview_id</th>\n",
       "      <th>interview_date</th>\n",
       "      <th>record_creation_date</th>\n",
       "      <th>venue</th>\n",
       "      <th>address_name</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state_/_province</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>interview_description</th>\n",
       "      <th>...</th>\n",
       "      <th>interviewer_relationship_1_to_storyteller_1</th>\n",
       "      <th>language_1</th>\n",
       "      <th>keywords_-_fixed_subjects</th>\n",
       "      <th>keywords_-_general</th>\n",
       "      <th>label1-fs</th>\n",
       "      <th>label2-fs</th>\n",
       "      <th>label3-fs</th>\n",
       "      <th>label1-g</th>\n",
       "      <th>label2-g</th>\n",
       "      <th>label3-g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MBY005668</td>\n",
       "      <td>2009/9/5 11:30</td>\n",
       "      <td>2009/9/5</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428</td>\n",
       "      <td>Rita Elvia Loya (38) habla con su esposo Omar ...</td>\n",
       "      <td>...</td>\n",
       "      <td>wife</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Achievements and Awards\\n\\nChildren\\n\\nCommuni...</td>\n",
       "      <td>bilingual\\n\\nBilingue\\n\\nChihuahua, Mexico\\n\\n...</td>\n",
       "      <td>Children</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>Immigration Stories</td>\n",
       "      <td>social beliefs and practices</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>memories of former times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MBY005712</td>\n",
       "      <td>2009/9/13 17:30</td>\n",
       "      <td>2009/9/13</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428</td>\n",
       "      <td>Cecilio Montes (46) habla con esposa Bertha Ja...</td>\n",
       "      <td>...</td>\n",
       "      <td>esposa</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Anniversaries\\n\\nChildren\\n\\nCommunity Busines...</td>\n",
       "      <td>accidents\\n\\nbaile\\n\\ncar accident\\n\\ncemetery...</td>\n",
       "      <td>Children</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>Immigration Stories</td>\n",
       "      <td>memories of former times</td>\n",
       "      <td>spouse</td>\n",
       "      <td>family tradition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MBY005713</td>\n",
       "      <td>2009/9/14 9:30</td>\n",
       "      <td>2009/9/14</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428</td>\n",
       "      <td>Alice talks about childhood.  Melissa remember...</td>\n",
       "      <td>...</td>\n",
       "      <td>grandmother</td>\n",
       "      <td>English</td>\n",
       "      <td>Birth\\n\\nBurials\\n\\nCancer\\n\\nChildcare\\n\\nChi...</td>\n",
       "      <td>alcohol\\n\\nbirth of first child\\n\\nchemotherap...</td>\n",
       "      <td>Parents</td>\n",
       "      <td>Children</td>\n",
       "      <td>Marriage</td>\n",
       "      <td>memories of growing up</td>\n",
       "      <td>memories of former times</td>\n",
       "      <td>family tradition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MBY005730</td>\n",
       "      <td>2009/9/18 12:30</td>\n",
       "      <td>2009/9/18</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428</td>\n",
       "      <td>Adolph Carranza Jr. (64) talks with friend Ele...</td>\n",
       "      <td>...</td>\n",
       "      <td>friend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Changes In Education\\n\\nCommunity Businesses\\n...</td>\n",
       "      <td>anecdotes (humorous but true stories)\\n\\nappea...</td>\n",
       "      <td>Parents</td>\n",
       "      <td>Schools</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>memories of growing up</td>\n",
       "      <td>social beliefs and practices</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MBY005764</td>\n",
       "      <td>2009/9/28 10:30</td>\n",
       "      <td>2009/9/28</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Public Library</td>\n",
       "      <td>Colorado Springs</td>\n",
       "      <td>CO</td>\n",
       "      <td>80911</td>\n",
       "      <td>Rosana interviews her friend Alberta about her...</td>\n",
       "      <td>...</td>\n",
       "      <td>friend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Education\\n\\nAchievements and Awards\\n\\nArmy\\n...</td>\n",
       "      <td>advocacy\\n\\nadvocate\\n\\ncollege\\n\\ndevelopment...</td>\n",
       "      <td>Schools</td>\n",
       "      <td>Children</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>memories of former times</td>\n",
       "      <td>school day memories</td>\n",
       "      <td>spouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  interview_id   interview_date record_creation_date                   venue  \\\n",
       "0    MBY005668   2009/9/5 11:30             2009/9/5  MobileBooth West (MBY)   \n",
       "1    MBY005712  2009/9/13 17:30            2009/9/13  MobileBooth West (MBY)   \n",
       "2    MBY005713   2009/9/14 9:30            2009/9/14  MobileBooth West (MBY)   \n",
       "3    MBY005730  2009/9/18 12:30            2009/9/18  MobileBooth West (MBY)   \n",
       "4    MBY005764  2009/9/28 10:30            2009/9/28  MobileBooth West (MBY)   \n",
       "\n",
       "       address_name                 street              city state_/_province  \\\n",
       "0  MobileBooth West  Paonia Public Library            Paonia               CO   \n",
       "1  MobileBooth West  Paonia Public Library            Paonia               CO   \n",
       "2  MobileBooth West  Paonia Public Library            Paonia               CO   \n",
       "3  MobileBooth West  Paonia Public Library            Paonia               CO   \n",
       "4  MobileBooth West         Public Library  Colorado Springs               CO   \n",
       "\n",
       "   postal_code                              interview_description  ...  \\\n",
       "0        81428  Rita Elvia Loya (38) habla con su esposo Omar ...  ...   \n",
       "1        81428  Cecilio Montes (46) habla con esposa Bertha Ja...  ...   \n",
       "2        81428  Alice talks about childhood.  Melissa remember...  ...   \n",
       "3        81428  Adolph Carranza Jr. (64) talks with friend Ele...  ...   \n",
       "4        80911  Rosana interviews her friend Alberta about her...  ...   \n",
       "\n",
       "  interviewer_relationship_1_to_storyteller_1 language_1  \\\n",
       "0                                        wife    Spanish   \n",
       "1                                      esposa    Spanish   \n",
       "2                                 grandmother    English   \n",
       "3                                      friend        NaN   \n",
       "4                                      friend        NaN   \n",
       "\n",
       "                           keywords_-_fixed_subjects  \\\n",
       "0  Achievements and Awards\\n\\nChildren\\n\\nCommuni...   \n",
       "1  Anniversaries\\n\\nChildren\\n\\nCommunity Busines...   \n",
       "2  Birth\\n\\nBurials\\n\\nCancer\\n\\nChildcare\\n\\nChi...   \n",
       "3  Changes In Education\\n\\nCommunity Businesses\\n...   \n",
       "4  Education\\n\\nAchievements and Awards\\n\\nArmy\\n...   \n",
       "\n",
       "                                  keywords_-_general label1-fs     label2-fs  \\\n",
       "0  bilingual\\n\\nBilingue\\n\\nChihuahua, Mexico\\n\\n...  Children  Workday Life   \n",
       "1  accidents\\n\\nbaile\\n\\ncar accident\\n\\ncemetery...  Children  Workday Life   \n",
       "2  alcohol\\n\\nbirth of first child\\n\\nchemotherap...   Parents      Children   \n",
       "3  anecdotes (humorous but true stories)\\n\\nappea...   Parents       Schools   \n",
       "4  advocacy\\n\\nadvocate\\n\\ncollege\\n\\ndevelopment...   Schools      Children   \n",
       "\n",
       "             label3-fs                      label1-g  \\\n",
       "0  Immigration Stories  social beliefs and practices   \n",
       "1  Immigration Stories      memories of former times   \n",
       "2             Marriage        memories of growing up   \n",
       "3         Workday Life        memories of growing up   \n",
       "4         Workday Life      memories of former times   \n",
       "\n",
       "                       label2-g                  label3-g  \n",
       "0                     ethnicity  memories of former times  \n",
       "1                        spouse          family tradition  \n",
       "2      memories of former times          family tradition  \n",
       "3  social beliefs and practices                 ethnicity  \n",
       "4           school day memories                    spouse  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_raw = pd.read_csv('Data/labels.csv')\n",
    "label_raw.columns = label_raw.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "label_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unnamed:_0</th>\n",
       "      <th>interview_id</th>\n",
       "      <th>interview_date_x</th>\n",
       "      <th>record_creation_date_x</th>\n",
       "      <th>venue_x</th>\n",
       "      <th>address_name_x</th>\n",
       "      <th>street_x</th>\n",
       "      <th>city_x</th>\n",
       "      <th>state_/_province_x</th>\n",
       "      <th>postal_code_x</th>\n",
       "      <th>...</th>\n",
       "      <th>interviewer_relationship_1_to_storyteller_1_y</th>\n",
       "      <th>language_1_y</th>\n",
       "      <th>keywords_-_fixed_subjects_y</th>\n",
       "      <th>keywords_-_general_y</th>\n",
       "      <th>label1-fs</th>\n",
       "      <th>label2-fs</th>\n",
       "      <th>label3-fs</th>\n",
       "      <th>label1-g</th>\n",
       "      <th>label2-g</th>\n",
       "      <th>label3-g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MBY005668</td>\n",
       "      <td>9/5/09 11:30</td>\n",
       "      <td>9/5/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>wife</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Achievements and Awards\\n\\nChildren\\n\\nCommuni...</td>\n",
       "      <td>bilingual\\n\\nBilingue\\n\\nChihuahua, Mexico\\n\\n...</td>\n",
       "      <td>Children</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>Immigration Stories</td>\n",
       "      <td>social beliefs and practices</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>memories of former times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MBY005712</td>\n",
       "      <td>9/13/09 17:30</td>\n",
       "      <td>9/13/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>esposa</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Anniversaries\\n\\nChildren\\n\\nCommunity Busines...</td>\n",
       "      <td>accidents\\n\\nbaile\\n\\ncar accident\\n\\ncemetery...</td>\n",
       "      <td>Children</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>Immigration Stories</td>\n",
       "      <td>memories of former times</td>\n",
       "      <td>spouse</td>\n",
       "      <td>family tradition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MBY005713</td>\n",
       "      <td>9/14/09 9:30</td>\n",
       "      <td>9/14/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>grandmother</td>\n",
       "      <td>English</td>\n",
       "      <td>Birth\\n\\nBurials\\n\\nCancer\\n\\nChildcare\\n\\nChi...</td>\n",
       "      <td>alcohol\\n\\nbirth of first child\\n\\nchemotherap...</td>\n",
       "      <td>Parents</td>\n",
       "      <td>Children</td>\n",
       "      <td>Marriage</td>\n",
       "      <td>memories of growing up</td>\n",
       "      <td>memories of former times</td>\n",
       "      <td>family tradition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MBY005730</td>\n",
       "      <td>9/18/09 12:30</td>\n",
       "      <td>9/18/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Paonia Public Library</td>\n",
       "      <td>Paonia</td>\n",
       "      <td>CO</td>\n",
       "      <td>81428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>friend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Changes In Education\\n\\nCommunity Businesses\\n...</td>\n",
       "      <td>anecdotes (humorous but true stories)\\n\\nappea...</td>\n",
       "      <td>Parents</td>\n",
       "      <td>Schools</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>memories of growing up</td>\n",
       "      <td>social beliefs and practices</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>MBY005764</td>\n",
       "      <td>9/28/09 10:30</td>\n",
       "      <td>9/28/09</td>\n",
       "      <td>MobileBooth West (MBY)</td>\n",
       "      <td>MobileBooth West</td>\n",
       "      <td>Public Library</td>\n",
       "      <td>Colorado Springs</td>\n",
       "      <td>CO</td>\n",
       "      <td>80911.0</td>\n",
       "      <td>...</td>\n",
       "      <td>friend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Education\\n\\nAchievements and Awards\\n\\nArmy\\n...</td>\n",
       "      <td>advocacy\\n\\nadvocate\\n\\ncollege\\n\\ndevelopment...</td>\n",
       "      <td>Schools</td>\n",
       "      <td>Children</td>\n",
       "      <td>Workday Life</td>\n",
       "      <td>memories of former times</td>\n",
       "      <td>school day memories</td>\n",
       "      <td>spouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unnamed:_0 interview_id interview_date_x record_creation_date_x  \\\n",
       "0           0    MBY005668     9/5/09 11:30                 9/5/09   \n",
       "1           2    MBY005712    9/13/09 17:30                9/13/09   \n",
       "2           3    MBY005713     9/14/09 9:30                9/14/09   \n",
       "3           4    MBY005730    9/18/09 12:30                9/18/09   \n",
       "4           6    MBY005764    9/28/09 10:30                9/28/09   \n",
       "\n",
       "                  venue_x    address_name_x               street_x  \\\n",
       "0  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library   \n",
       "1  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library   \n",
       "2  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library   \n",
       "3  MobileBooth West (MBY)  MobileBooth West  Paonia Public Library   \n",
       "4  MobileBooth West (MBY)  MobileBooth West         Public Library   \n",
       "\n",
       "             city_x state_/_province_x  postal_code_x  ...  \\\n",
       "0            Paonia                 CO        81428.0  ...   \n",
       "1            Paonia                 CO        81428.0  ...   \n",
       "2            Paonia                 CO        81428.0  ...   \n",
       "3            Paonia                 CO        81428.0  ...   \n",
       "4  Colorado Springs                 CO        80911.0  ...   \n",
       "\n",
       "  interviewer_relationship_1_to_storyteller_1_y language_1_y  \\\n",
       "0                                          wife      Spanish   \n",
       "1                                        esposa      Spanish   \n",
       "2                                   grandmother      English   \n",
       "3                                        friend          NaN   \n",
       "4                                        friend          NaN   \n",
       "\n",
       "                         keywords_-_fixed_subjects_y  \\\n",
       "0  Achievements and Awards\\n\\nChildren\\n\\nCommuni...   \n",
       "1  Anniversaries\\n\\nChildren\\n\\nCommunity Busines...   \n",
       "2  Birth\\n\\nBurials\\n\\nCancer\\n\\nChildcare\\n\\nChi...   \n",
       "3  Changes In Education\\n\\nCommunity Businesses\\n...   \n",
       "4  Education\\n\\nAchievements and Awards\\n\\nArmy\\n...   \n",
       "\n",
       "                                keywords_-_general_y label1-fs     label2-fs  \\\n",
       "0  bilingual\\n\\nBilingue\\n\\nChihuahua, Mexico\\n\\n...  Children  Workday Life   \n",
       "1  accidents\\n\\nbaile\\n\\ncar accident\\n\\ncemetery...  Children  Workday Life   \n",
       "2  alcohol\\n\\nbirth of first child\\n\\nchemotherap...   Parents      Children   \n",
       "3  anecdotes (humorous but true stories)\\n\\nappea...   Parents       Schools   \n",
       "4  advocacy\\n\\nadvocate\\n\\ncollege\\n\\ndevelopment...   Schools      Children   \n",
       "\n",
       "             label3-fs                      label1-g  \\\n",
       "0  Immigration Stories  social beliefs and practices   \n",
       "1  Immigration Stories      memories of former times   \n",
       "2             Marriage        memories of growing up   \n",
       "3         Workday Life        memories of growing up   \n",
       "4         Workday Life      memories of former times   \n",
       "\n",
       "                       label2-g                  label3-g  \n",
       "0                     ethnicity  memories of former times  \n",
       "1                        spouse          family tradition  \n",
       "2      memories of former times          family tradition  \n",
       "3  social beliefs and practices                 ethnicity  \n",
       "4           school day memories                    spouse  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = transcript_raw.merge(label_raw, on='interview_id')\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(332, 84)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>google_transcript</th>\n",
       "      <th>label3-g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I mean I'm already so my lawyer Singapore and ...</td>\n",
       "      <td>memories of former times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>okay mean Hombres es el Amante Samira cincuent...</td>\n",
       "      <td>family tradition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my name is Melissa Humphrey I'm 26 today's dat...</td>\n",
       "      <td>family tradition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello my name is Adolfo Carranza Junior and I'...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my number is rational and pony my name is Rose...</td>\n",
       "      <td>spouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   google_transcript                  label3-g\n",
       "0  I mean I'm already so my lawyer Singapore and ...  memories of former times\n",
       "1  okay mean Hombres es el Amante Samira cincuent...          family tradition\n",
       "2  my name is Melissa Humphrey I'm 26 today's dat...          family tradition\n",
       "3  hello my name is Adolfo Carranza Junior and I'...                 ethnicity\n",
       "4  my number is rational and pony my name is Rose...                    spouse"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = train_raw[['google_transcript', LABEL]]\n",
    "train_raw.reset_index(inplace=True, drop=True)\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anecdotes (humorous but true stories)\n",
      "college\n",
      "economic beliefs and practices\n",
      "ethnicity\n",
      "family characters\n",
      "family naming and nicknames\n",
      "family tradition\n",
      "memories of former times\n",
      "political beliefs and practices\n",
      "religious beliefs and practices\n",
      "school day memories\n",
      "spouse\n"
     ]
    }
   ],
   "source": [
    "for l in np.unique(train_raw[LABEL]):\n",
    "  print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I mean I'm already so my lawyer Singapore and ...</td>\n",
       "      <td>memories of former times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>okay mean Hombres es el Amante Samira cincuent...</td>\n",
       "      <td>family tradition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my name is Melissa Humphrey I'm 26 today's dat...</td>\n",
       "      <td>family tradition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello my name is Adolfo Carranza Junior and I'...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my number is rational and pony my name is Rose...</td>\n",
       "      <td>spouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                     label\n",
       "0  I mean I'm already so my lawyer Singapore and ...  memories of former times\n",
       "1  okay mean Hombres es el Amante Samira cincuent...          family tradition\n",
       "2  my name is Melissa Humphrey I'm 26 today's dat...          family tradition\n",
       "3  hello my name is Adolfo Carranza Junior and I'...                 ethnicity\n",
       "4  my number is rational and pony my name is Rose...                    spouse"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw=train_raw.rename(columns = {'google_transcript':'text', LABEL:'label'})\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I mean I'm already so my lawyer Singapore and ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>okay mean Hombres es el Amante Samira cincuent...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my name is Melissa Humphrey I'm 26 today's dat...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello my name is Adolfo Carranza Junior and I'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my number is rational and pony my name is Rose...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I mean I'm already so my lawyer Singapore and ...      7\n",
       "1  okay mean Hombres es el Amante Samira cincuent...      6\n",
       "2  my name is Melissa Humphrey I'm 26 today's dat...      6\n",
       "3  hello my name is Adolfo Carranza Junior and I'...      3\n",
       "4  my number is rational and pony my name is Rose...     11"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "LE = LabelEncoder()\n",
    "train_raw['label'] = LE.fit_transform(train_raw['label'])\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(np.unique(train_raw['label']))\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r = train_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>my name is Samantha Garcia in 21 today's date ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>but it was hilarious I have 24 years old today...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>okay my name is Juan Carlos Padilla I'm 34 yea...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>my name is Lisa Padilla I'm 47 today is March ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Santa Monica Garcia then go cuarenta siete ano...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "260  my name is Samantha Garcia in 21 today's date ...      7\n",
       "90   but it was hilarious I have 24 years old today...      3\n",
       "163  okay my name is Juan Carlos Padilla I'm 34 yea...      3\n",
       "188  my name is Lisa Padilla I'm 47 today is March ...      3\n",
       "53   Santa Monica Garcia then go cuarenta siete ano...      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_r = train_r.reindex(np.random.permutation(train_r.index))\n",
    "train_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_txt(text):\n",
    "  text = re.sub(\"'\", \"\",text)\n",
    "  text=re.sub(\"(\\\\W)+\",\" \",text)    \n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>my name is Samantha Garcia in 21 todays date i...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>but it was hilarious I have 24 years old today...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>okay my name is Juan Carlos Padilla Im 34 year...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>my name is Lisa Padilla Im 47 today is March 1...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Santa Monica Garcia then go cuarenta siete ano...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "260  my name is Samantha Garcia in 21 todays date i...      7\n",
       "90   but it was hilarious I have 24 years old today...      3\n",
       "163  okay my name is Juan Carlos Padilla Im 34 year...      3\n",
       "188  my name is Lisa Padilla Im 47 today is March 1...      3\n",
       "53   Santa Monica Garcia then go cuarenta siete ano...      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_r['text']  = train_r.text.apply(clean_txt)\n",
    "train_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Douglas Sanchez 18 January 16th 2010 Yuma Ariz...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hi my name is Heidi Christine Johnson Im 38 ye...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>hello my name is Catalina Correa age and my th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>hello my name is Ernesto Cassidys Im 25 years ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>and you know Melissa Lopez Chavez single cincu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "79   Douglas Sanchez 18 January 16th 2010 Yuma Ariz...      3\n",
       "17   hi my name is Heidi Christine Johnson Im 38 ye...      7\n",
       "75   hello my name is Catalina Correa age and my th...      3\n",
       "237  hello my name is Ernesto Cassidys Im 25 years ...      3\n",
       "263  and you know Melissa Lopez Chavez single cincu...      3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(train_r, test_size=0.2)\n",
    "while(len(np.unique(train.label)) != num_labels):\n",
    "      train, val = train_test_split(train_r, test_size=0.2)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Douglas Sanchez 18 January 16th 2010 Yuma Ariz...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi my name is Heidi Christine Johnson Im 38 ye...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Douglas Sanchez 18 January 16th 2010 Yuma Ariz...      3\n",
       "1  hi my name is Heidi Christine Johnson Im 38 ye...      7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.reset_index(drop=True, inplace=True)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>me nombre zombie Salcedo unfortunately it stay...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my name is Erin Selena Reyes my age is actuall...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  me nombre zombie Salcedo unfortunately it stay...      3\n",
       "1  my name is Erin Selena Reyes my age is actuall...      3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.reset_index(drop=True, inplace=True)\n",
    "val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67, 2), (265, 2))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-tensorflow in c:\\users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages (from bert-tensorflow) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "#Installing BERT module\n",
    "!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Importing BERT modules\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Model output directory: ./bert_output/ *****\n"
     ]
    }
   ],
   "source": [
    "# Set the output directory for saving model file\n",
    "OUTPUT_DIR = './bert_output/'\n",
    "\n",
    "#@markdown Whether or not to clear/delete the directory and create a new one\n",
    "DO_DELETE = True #@param {type:\"boolean\"}\n",
    "\n",
    "if DO_DELETE:\n",
    "  try:\n",
    "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape : (265, 2)\n",
      "Validation Set Shape : (67, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Shape :\", train.shape)\n",
    "print(\"Validation Set Shape :\", val.shape)\n",
    "# print(\"Test Set Shape :\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_COLUMN = 'text'\n",
    "LABEL_COLUMN = 'label'\n",
    "# The list containing all the classes (train['SECTION'].unique())\n",
    "label_list = [x for x in np.unique(train.label)]\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(text1):\n",
    "  l_total = []\n",
    "  l_parcial = []\n",
    "  if len(text1.split())//150 >0:\n",
    "    n = len(text1.split())//150\n",
    "  else: \n",
    "    n = 1\n",
    "  for w in range(n):\n",
    "    if w == 0:\n",
    "      l_parcial = text1.split()[:200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "    else:\n",
    "      l_parcial = text1.split()[w*150:w*150 + 200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "  return l_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Douglas Sanchez 18 January 16th 2010 Yuma Ariz...</td>\n",
       "      <td>3</td>\n",
       "      <td>[Douglas Sanchez 18 January 16th 2010 Yuma Ari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi my name is Heidi Christine Johnson Im 38 ye...</td>\n",
       "      <td>7</td>\n",
       "      <td>[hi my name is Heidi Christine Johnson Im 38 y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello my name is Catalina Correa age and my th...</td>\n",
       "      <td>3</td>\n",
       "      <td>[hello my name is Catalina Correa age and my t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello my name is Ernesto Cassidys Im 25 years ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[hello my name is Ernesto Cassidys Im 25 years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and you know Melissa Lopez Chavez single cincu...</td>\n",
       "      <td>3</td>\n",
       "      <td>[and you know Melissa Lopez Chavez single cinc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Douglas Sanchez 18 January 16th 2010 Yuma Ariz...      3   \n",
       "1  hi my name is Heidi Christine Johnson Im 38 ye...      7   \n",
       "2  hello my name is Catalina Correa age and my th...      3   \n",
       "3  hello my name is Ernesto Cassidys Im 25 years ...      3   \n",
       "4  and you know Melissa Lopez Chavez single cincu...      3   \n",
       "\n",
       "                                          text_split  \n",
       "0  [Douglas Sanchez 18 January 16th 2010 Yuma Ari...  \n",
       "1  [hi my name is Heidi Christine Johnson Im 38 y...  \n",
       "2  [hello my name is Catalina Correa age and my t...  \n",
       "3  [hello my name is Ernesto Cassidys Im 25 years...  \n",
       "4  [and you know Melissa Lopez Chavez single cinc...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text_split'] = train[DATA_COLUMN].apply(get_split)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>me nombre zombie Salcedo unfortunately it stay...</td>\n",
       "      <td>3</td>\n",
       "      <td>[me nombre zombie Salcedo unfortunately it sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my name is Erin Selena Reyes my age is actuall...</td>\n",
       "      <td>3</td>\n",
       "      <td>[my name is Erin Selena Reyes my age is actual...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  me nombre zombie Salcedo unfortunately it stay...      3   \n",
       "1  my name is Erin Selena Reyes my age is actuall...      3   \n",
       "\n",
       "                                          text_split  \n",
       "0  [me nombre zombie Salcedo unfortunately it sta...  \n",
       "1  [my name is Erin Selena Reyes my age is actual...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['text_split'] = val[DATA_COLUMN].apply(get_split)\n",
    "val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7756, 7756, 7756)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_l = []\n",
    "label_l = []\n",
    "index_l =[]\n",
    "for idx,row in train.iterrows():\n",
    "  for l in row['text_split']:\n",
    "    train_l.append(l)\n",
    "    label_l.append(row['label'])\n",
    "    index_l.append(idx)\n",
    "len(train_l), len(label_l), len(index_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075, 2075, 2075)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_l = []\n",
    "val_label_l = []\n",
    "val_index_l = []\n",
    "for idx,row in val.iterrows():\n",
    "  for l in row['text_split']:\n",
    "    val_l.append(l)\n",
    "    val_label_l.append(row['label'])\n",
    "    val_index_l.append(idx)\n",
    "len(val_l), len(val_label_l), len(val_index_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Douglas Sanchez 18 January 16th 2010 Yuma Ariz...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that that particular time contrary to now ther...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bar called The Cameo and at that time traffic ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>was one of the very first projects I ever did ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in and it was restricted and I started bring I...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Douglas Sanchez 18 January 16th 2010 Yuma Ariz...      3\n",
       "1  that that particular time contrary to now ther...      3\n",
       "2  bar called The Cameo and at that time traffic ...      3\n",
       "3  was one of the very first projects I ever did ...      3\n",
       "4  in and it was restricted and I started bring I...      3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame({DATA_COLUMN:train_l, LABEL_COLUMN:label_l})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>me nombre zombie Salcedo unfortunately it stay...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>can be left alone in Spanish books what Im int...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to you yet cast device to spend all 1 sueno de...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TransCanada Latinas much has been said when yo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC C People are getting a list A to Z Pinot co...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  me nombre zombie Salcedo unfortunately it stay...      3\n",
       "1  can be left alone in Spanish books what Im int...      3\n",
       "2  to you yet cast device to spend all 1 sueno de...      3\n",
       "3  TransCanada Latinas much has been said when yo...      3\n",
       "4  CC C People are getting a list A to Z Pinot co...      3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.DataFrame({DATA_COLUMN:val_l, LABEL_COLUMN:val_label_l})\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_InputExamples = train_df.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "val_InputExamples = val_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       <bert.run_classifier.InputExample object at 0x...\n",
       "1       <bert.run_classifier.InputExample object at 0x...\n",
       "2       <bert.run_classifier.InputExample object at 0x...\n",
       "3       <bert.run_classifier.InputExample object at 0x...\n",
       "4       <bert.run_classifier.InputExample object at 0x...\n",
       "                              ...                        \n",
       "7751    <bert.run_classifier.InputExample object at 0x...\n",
       "7752    <bert.run_classifier.InputExample object at 0x...\n",
       "7753    <bert.run_classifier.InputExample object at 0x...\n",
       "7754    <bert.run_classifier.InputExample object at 0x...\n",
       "7755    <bert.run_classifier.InputExample object at 0x...\n",
       "Length: 7756, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 - guid of training set :  None\n",
      "\n",
      "__________\n",
      "Row 0 - text_a of training set :  Douglas Sanchez 18 January 16th 2010 Yuma Arizona Michael is my friend Michael H Bachman Im 67 January 16th 2010 in Yuma Arizona my relationship is a friend and mentor Im so Michael what brought you to Yuma and when you got here or just describe the LGBT community when my boyfriend of 17 years died in the car crash in Fresno California made a decision then I would go and it was simultaneous that I would go down to Yuma come over to Yuma because my father was also ill and he was about to die he we had about six months so I decided to just take a year and come down here and stay with him and in that six months time in Yuma got involved immediately with the community the Yuma Fine Arts the again whatever was going on I just got involved in it and that that particular time contrary to now there was a tremendously robots the gay community which I found appealing because every cuz it was congenial it was neighborhood style It was friendly and then when my father passed I stayed on to another 6 months to help my mother to\n",
      "\n",
      "__________\n",
      "Row 0 - text_b of training set :  None\n",
      "\n",
      "__________\n",
      "Row 0 - label of training set :  3\n"
     ]
    }
   ],
   "source": [
    "print(\"Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n",
    "print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples.iloc[0].text_a)\n",
    "print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples.iloc[0].text_b)\n",
    "print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples.iloc[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['douglas', 'sanchez', '18', 'january', '16th', '2010', 'yu', '##ma', 'arizona', 'michael', 'is', 'my', 'friend', 'michael', 'h', 'bach', '##man', 'im', '67', 'january', '16th', '2010', 'in', 'yu', '##ma', 'arizona', 'my', 'relationship', 'is', 'a', 'friend', 'and', 'mentor', 'im', 'so', 'michael', 'what', 'brought', 'you', 'to', 'yu', '##ma', 'and', 'when', 'you', 'got', 'here', 'or', 'just', 'describe', 'the', 'lgbt', 'community', 'when', 'my', 'boyfriend', 'of', '17', 'years', 'died', 'in', 'the', 'car', 'crash', 'in', 'fresno', 'california', 'made', 'a', 'decision', 'then', 'i', 'would', 'go', 'and', 'it', 'was', 'simultaneous', 'that', 'i', 'would', 'go', 'down', 'to', 'yu', '##ma', 'come', 'over', 'to', 'yu', '##ma', 'because', 'my', 'father', 'was', 'also', 'ill', 'and', 'he', 'was', 'about', 'to', 'die', 'he', 'we', 'had', 'about', 'six', 'months', 'so', 'i', 'decided', 'to', 'just', 'take', 'a', 'year', 'and', 'come', 'down', 'here', 'and', 'stay', 'with', 'him', 'and', 'in', 'that', 'six', 'months', 'time', 'in', 'yu', '##ma', 'got', 'involved', 'immediately', 'with', 'the', 'community', 'the', 'yu', '##ma', 'fine', 'arts', 'the', 'again', 'whatever', 'was', 'going', 'on', 'i', 'just', 'got', 'involved', 'in', 'it', 'and', 'that', 'that', 'particular', 'time', 'contrary', 'to', 'now', 'there', 'was', 'a', 'tremendous', '##ly', 'robots', 'the', 'gay', 'community', 'which', 'i', 'found', 'appealing', 'because', 'every', 'cu', '##z', 'it', 'was', 'cong', '##enia', '##l', 'it', 'was', 'neighborhood', 'style', 'it', 'was', 'friendly', 'and', 'then', 'when', 'my', 'father', 'passed', 'i', 'stayed', 'on', 'to', 'another', '6', 'months', 'to', 'help', 'my', 'mother', 'to']\n"
     ]
    }
   ],
   "source": [
    "#Here is what the tokenised sample of the first training set observation looks like\n",
    "print(tokenizer.tokenize(train_InputExamples.iloc[0].text_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 7756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 7756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] douglas sanchez 18 january 16th 2010 yu ##ma arizona michael is my friend michael h bach ##man im 67 january 16th 2010 in yu ##ma arizona my relationship is a friend and mentor im so michael what brought you to yu ##ma and when you got here or just describe the lgbt community when my boyfriend of 17 years died in the car crash in fresno california made a decision then i would go and it was simultaneous that i would go down to yu ##ma come over to yu ##ma because my father was also ill and he was about to die he we had about six months so i decided to just take a year and come down here and stay with him and in that six months time in yu ##ma got involved immediately with the community the yu ##ma fine arts the again whatever was going on i just got involved in it and that that particular time contrary to now there was a tremendous ##ly robots the gay community which i found appealing because every cu ##z it was cong ##enia ##l it was neighborhood style it was friendly and then when my [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] douglas sanchez 18 january 16th 2010 yu ##ma arizona michael is my friend michael h bach ##man im 67 january 16th 2010 in yu ##ma arizona my relationship is a friend and mentor im so michael what brought you to yu ##ma and when you got here or just describe the lgbt community when my boyfriend of 17 years died in the car crash in fresno california made a decision then i would go and it was simultaneous that i would go down to yu ##ma come over to yu ##ma because my father was also ill and he was about to die he we had about six months so i decided to just take a year and come down here and stay with him and in that six months time in yu ##ma got involved immediately with the community the yu ##ma fine arts the again whatever was going on i just got involved in it and that that particular time contrary to now there was a tremendous ##ly robots the gay community which i found appealing because every cu ##z it was cong ##enia ##l it was neighborhood style it was friendly and then when my [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5203 10568 2324 2254 5767 2230 9805 2863 5334 2745 2003 2026 2767 2745 1044 10384 2386 10047 6163 2254 5767 2230 1999 9805 2863 5334 2026 3276 2003 1037 2767 1998 10779 10047 2061 2745 2054 2716 2017 2000 9805 2863 1998 2043 2017 2288 2182 2030 2074 6235 1996 12010 2451 2043 2026 6898 1997 2459 2086 2351 1999 1996 2482 5823 1999 20840 2662 2081 1037 3247 2059 1045 2052 2175 1998 2009 2001 17424 2008 1045 2052 2175 2091 2000 9805 2863 2272 2058 2000 9805 2863 2138 2026 2269 2001 2036 5665 1998 2002 2001 2055 2000 3280 2002 2057 2018 2055 2416 2706 2061 1045 2787 2000 2074 2202 1037 2095 1998 2272 2091 2182 1998 2994 2007 2032 1998 1999 2008 2416 2706 2051 1999 9805 2863 2288 2920 3202 2007 1996 2451 1996 9805 2863 2986 2840 1996 2153 3649 2001 2183 2006 1045 2074 2288 2920 1999 2009 1998 2008 2008 3327 2051 10043 2000 2085 2045 2001 1037 14388 2135 13507 1996 5637 2451 2029 1045 2179 16004 2138 2296 12731 2480 2009 2001 26478 19825 2140 2009 2001 5101 2806 2009 2001 5379 1998 2059 2043 2026 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 5203 10568 2324 2254 5767 2230 9805 2863 5334 2745 2003 2026 2767 2745 1044 10384 2386 10047 6163 2254 5767 2230 1999 9805 2863 5334 2026 3276 2003 1037 2767 1998 10779 10047 2061 2745 2054 2716 2017 2000 9805 2863 1998 2043 2017 2288 2182 2030 2074 6235 1996 12010 2451 2043 2026 6898 1997 2459 2086 2351 1999 1996 2482 5823 1999 20840 2662 2081 1037 3247 2059 1045 2052 2175 1998 2009 2001 17424 2008 1045 2052 2175 2091 2000 9805 2863 2272 2058 2000 9805 2863 2138 2026 2269 2001 2036 5665 1998 2002 2001 2055 2000 3280 2002 2057 2018 2055 2416 2706 2061 1045 2787 2000 2074 2202 1037 2095 1998 2272 2091 2182 1998 2994 2007 2032 1998 1999 2008 2416 2706 2051 1999 9805 2863 2288 2920 3202 2007 1996 2451 1996 9805 2863 2986 2840 1996 2153 3649 2001 2183 2006 1045 2074 2288 2920 1999 2009 1998 2008 2008 3327 2051 10043 2000 2085 2045 2001 1037 14388 2135 13507 1996 5637 2451 2029 1045 2179 16004 2138 2296 12731 2480 2009 2001 26478 19825 2140 2009 2001 5101 2806 2009 2001 5379 1998 2059 2043 2026 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] that that particular time contrary to now there was a tremendous ##ly robots the gay community which i found appealing because every cu ##z it was cong ##enia ##l it was neighborhood style it was friendly and then when my father passed i stayed on to another 6 months to help my mother to the gr ##ieving process which then came out to a year and in that years time i fell in love with the whole area the desert the off road ##ing the everything that they could do and also the cong ##enia ##l gay atmosphere that was here at that time because the g ##lb we didn ##t have initials fa ##q then buddy be it was you just got into projects everywhere we all had and then people gay people are sitting on the city council i mean it was terrific back then hit and that was a lot of it was run out of a little bar called the cameo and at that time traffic bar cu ##z we had such a grand time there miss friendly and it was the way i went all that we went from noon until i don [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] that that particular time contrary to now there was a tremendous ##ly robots the gay community which i found appealing because every cu ##z it was cong ##enia ##l it was neighborhood style it was friendly and then when my father passed i stayed on to another 6 months to help my mother to the gr ##ieving process which then came out to a year and in that years time i fell in love with the whole area the desert the off road ##ing the everything that they could do and also the cong ##enia ##l gay atmosphere that was here at that time because the g ##lb we didn ##t have initials fa ##q then buddy be it was you just got into projects everywhere we all had and then people gay people are sitting on the city council i mean it was terrific back then hit and that was a lot of it was run out of a little bar called the cameo and at that time traffic bar cu ##z we had such a grand time there miss friendly and it was the way i went all that we went from noon until i don [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2008 2008 3327 2051 10043 2000 2085 2045 2001 1037 14388 2135 13507 1996 5637 2451 2029 1045 2179 16004 2138 2296 12731 2480 2009 2001 26478 19825 2140 2009 2001 5101 2806 2009 2001 5379 1998 2059 2043 2026 2269 2979 1045 4370 2006 2000 2178 1020 2706 2000 2393 2026 2388 2000 1996 24665 25587 2832 2029 2059 2234 2041 2000 1037 2095 1998 1999 2008 2086 2051 1045 3062 1999 2293 2007 1996 2878 2181 1996 5532 1996 2125 2346 2075 1996 2673 2008 2027 2071 2079 1998 2036 1996 26478 19825 2140 5637 7224 2008 2001 2182 2012 2008 2051 2138 1996 1043 20850 2057 2134 2102 2031 20381 6904 4160 2059 8937 2022 2009 2001 2017 2074 2288 2046 3934 7249 2057 2035 2018 1998 2059 2111 5637 2111 2024 3564 2006 1996 2103 2473 1045 2812 2009 2001 27547 2067 2059 2718 1998 2008 2001 1037 2843 1997 2009 2001 2448 2041 1997 1037 2210 3347 2170 1996 12081 1998 2012 2008 2051 4026 3347 12731 2480 2057 2018 2107 1037 2882 2051 2045 3335 5379 1998 2009 2001 1996 2126 1045 2253 2035 2008 2057 2253 2013 11501 2127 1045 2123 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2008 2008 3327 2051 10043 2000 2085 2045 2001 1037 14388 2135 13507 1996 5637 2451 2029 1045 2179 16004 2138 2296 12731 2480 2009 2001 26478 19825 2140 2009 2001 5101 2806 2009 2001 5379 1998 2059 2043 2026 2269 2979 1045 4370 2006 2000 2178 1020 2706 2000 2393 2026 2388 2000 1996 24665 25587 2832 2029 2059 2234 2041 2000 1037 2095 1998 1999 2008 2086 2051 1045 3062 1999 2293 2007 1996 2878 2181 1996 5532 1996 2125 2346 2075 1996 2673 2008 2027 2071 2079 1998 2036 1996 26478 19825 2140 5637 7224 2008 2001 2182 2012 2008 2051 2138 1996 1043 20850 2057 2134 2102 2031 20381 6904 4160 2059 8937 2022 2009 2001 2017 2074 2288 2046 3934 7249 2057 2035 2018 1998 2059 2111 5637 2111 2024 3564 2006 1996 2103 2473 1045 2812 2009 2001 27547 2067 2059 2718 1998 2008 2001 1037 2843 1997 2009 2001 2448 2041 1997 1037 2210 3347 2170 1996 12081 1998 2012 2008 2051 4026 3347 12731 2480 2057 2018 2107 1037 2882 2051 2045 3335 5379 1998 2009 2001 1996 2126 1045 2253 2035 2008 2057 2253 2013 11501 2127 1045 2123 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] bar called the cameo and at that time traffic bar cu ##z we had such a grand time there miss friendly and it was the way i went all that we went from noon until i don ##t know if you want to or too end you never had the sense of dread or impatience or any of those things that i find in most large cities so i that ##s why im really done iv ##e decided to stay because it was good and there was an i saw also something my parents had taught me a long time ago to get involved of the stuff and i saw it needs popping up there was a need for the g ##lb ##t community to do more activism there was certainly a need for the disabled community that was here at that particular time age was just coming up and it it done im inside that was one of the very first projects i ever did in this town was we couldn ##t when i when i first met my first aids person here in yu ##ma that was only to a female and a male that i [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] bar called the cameo and at that time traffic bar cu ##z we had such a grand time there miss friendly and it was the way i went all that we went from noon until i don ##t know if you want to or too end you never had the sense of dread or impatience or any of those things that i find in most large cities so i that ##s why im really done iv ##e decided to stay because it was good and there was an i saw also something my parents had taught me a long time ago to get involved of the stuff and i saw it needs popping up there was a need for the g ##lb ##t community to do more activism there was certainly a need for the disabled community that was here at that particular time age was just coming up and it it done im inside that was one of the very first projects i ever did in this town was we couldn ##t when i when i first met my first aids person here in yu ##ma that was only to a female and a male that i [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3347 2170 1996 12081 1998 2012 2008 2051 4026 3347 12731 2480 2057 2018 2107 1037 2882 2051 2045 3335 5379 1998 2009 2001 1996 2126 1045 2253 2035 2008 2057 2253 2013 11501 2127 1045 2123 2102 2113 2065 2017 2215 2000 2030 2205 2203 2017 2196 2018 1996 3168 1997 14436 2030 28011 2030 2151 1997 2216 2477 2008 1045 2424 1999 2087 2312 3655 2061 1045 2008 2015 2339 10047 2428 2589 4921 2063 2787 2000 2994 2138 2009 2001 2204 1998 2045 2001 2019 1045 2387 2036 2242 2026 3008 2018 4036 2033 1037 2146 2051 3283 2000 2131 2920 1997 1996 4933 1998 1045 2387 2009 3791 20095 2039 2045 2001 1037 2342 2005 1996 1043 20850 2102 2451 2000 2079 2062 16841 2045 2001 5121 1037 2342 2005 1996 9776 2451 2008 2001 2182 2012 2008 3327 2051 2287 2001 2074 2746 2039 1998 2009 2009 2589 10047 2503 2008 2001 2028 1997 1996 2200 2034 3934 1045 2412 2106 1999 2023 2237 2001 2057 2481 2102 2043 1045 2043 1045 2034 2777 2026 2034 8387 2711 2182 1999 9805 2863 2008 2001 2069 2000 1037 2931 1998 1037 3287 2008 1045 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3347 2170 1996 12081 1998 2012 2008 2051 4026 3347 12731 2480 2057 2018 2107 1037 2882 2051 2045 3335 5379 1998 2009 2001 1996 2126 1045 2253 2035 2008 2057 2253 2013 11501 2127 1045 2123 2102 2113 2065 2017 2215 2000 2030 2205 2203 2017 2196 2018 1996 3168 1997 14436 2030 28011 2030 2151 1997 2216 2477 2008 1045 2424 1999 2087 2312 3655 2061 1045 2008 2015 2339 10047 2428 2589 4921 2063 2787 2000 2994 2138 2009 2001 2204 1998 2045 2001 2019 1045 2387 2036 2242 2026 3008 2018 4036 2033 1037 2146 2051 3283 2000 2131 2920 1997 1996 4933 1998 1045 2387 2009 3791 20095 2039 2045 2001 1037 2342 2005 1996 1043 20850 2102 2451 2000 2079 2062 16841 2045 2001 5121 1037 2342 2005 1996 9776 2451 2008 2001 2182 2012 2008 3327 2051 2287 2001 2074 2746 2039 1998 2009 2009 2589 10047 2503 2008 2001 2028 1997 1996 2200 2034 3934 1045 2412 2106 1999 2023 2237 2001 2057 2481 2102 2043 1045 2043 1045 2034 2777 2026 2034 8387 2711 2182 1999 9805 2863 2008 2001 2069 2000 1037 2931 1998 1037 3287 2008 1045 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] was one of the very first projects i ever did in this town was we couldn ##t when i when i first met my first aids person here in yu ##ma that was only to a female and a male that i wanted to i went over to the health department and there were no services and i went to the hospital and there were no services and no one wanted to talk about it no i had to do anything about it so joel the bar owner and i sat down and we decide well okay i use going to open his bar on a saturday afternoon were going to put out a lot of information and we started holding seminars prevention seminars target group was the kids we threw sheets over all the liquor which allowed his sons of those laws back then allowed us to have kids to come in and it was restricted and i started bring i brought my personal physician down i finally coe ##rce ##d some hospital people to come and got the health department health department to come out and then one one day i decided what we have to [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] was one of the very first projects i ever did in this town was we couldn ##t when i when i first met my first aids person here in yu ##ma that was only to a female and a male that i wanted to i went over to the health department and there were no services and i went to the hospital and there were no services and no one wanted to talk about it no i had to do anything about it so joel the bar owner and i sat down and we decide well okay i use going to open his bar on a saturday afternoon were going to put out a lot of information and we started holding seminars prevention seminars target group was the kids we threw sheets over all the liquor which allowed his sons of those laws back then allowed us to have kids to come in and it was restricted and i started bring i brought my personal physician down i finally coe ##rce ##d some hospital people to come and got the health department health department to come out and then one one day i decided what we have to [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2001 2028 1997 1996 2200 2034 3934 1045 2412 2106 1999 2023 2237 2001 2057 2481 2102 2043 1045 2043 1045 2034 2777 2026 2034 8387 2711 2182 1999 9805 2863 2008 2001 2069 2000 1037 2931 1998 1037 3287 2008 1045 2359 2000 1045 2253 2058 2000 1996 2740 2533 1998 2045 2020 2053 2578 1998 1045 2253 2000 1996 2902 1998 2045 2020 2053 2578 1998 2053 2028 2359 2000 2831 2055 2009 2053 1045 2018 2000 2079 2505 2055 2009 2061 8963 1996 3347 3954 1998 1045 2938 2091 1998 2057 5630 2092 3100 1045 2224 2183 2000 2330 2010 3347 2006 1037 5095 5027 2020 2183 2000 2404 2041 1037 2843 1997 2592 1998 2057 2318 3173 17239 9740 17239 4539 2177 2001 1996 4268 2057 4711 8697 2058 2035 1996 13207 2029 3039 2010 4124 1997 2216 4277 2067 2059 3039 2149 2000 2031 4268 2000 2272 1999 1998 2009 2001 7775 1998 1045 2318 3288 1045 2716 2026 3167 7522 2091 1045 2633 24873 19170 2094 2070 2902 2111 2000 2272 1998 2288 1996 2740 2533 2740 2533 2000 2272 2041 1998 2059 2028 2028 2154 1045 2787 2054 2057 2031 2000 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2001 2028 1997 1996 2200 2034 3934 1045 2412 2106 1999 2023 2237 2001 2057 2481 2102 2043 1045 2043 1045 2034 2777 2026 2034 8387 2711 2182 1999 9805 2863 2008 2001 2069 2000 1037 2931 1998 1037 3287 2008 1045 2359 2000 1045 2253 2058 2000 1996 2740 2533 1998 2045 2020 2053 2578 1998 1045 2253 2000 1996 2902 1998 2045 2020 2053 2578 1998 2053 2028 2359 2000 2831 2055 2009 2053 1045 2018 2000 2079 2505 2055 2009 2061 8963 1996 3347 3954 1998 1045 2938 2091 1998 2057 5630 2092 3100 1045 2224 2183 2000 2330 2010 3347 2006 1037 5095 5027 2020 2183 2000 2404 2041 1037 2843 1997 2592 1998 2057 2318 3173 17239 9740 17239 4539 2177 2001 1996 4268 2057 4711 8697 2058 2035 1996 13207 2029 3039 2010 4124 1997 2216 4277 2067 2059 3039 2149 2000 2031 4268 2000 2272 1999 1998 2009 2001 7775 1998 1045 2318 3288 1045 2716 2026 3167 7522 2091 1045 2633 24873 19170 2094 2070 2902 2111 2000 2272 1998 2288 1996 2740 2533 2740 2533 2000 2272 2041 1998 2059 2028 2028 2154 1045 2787 2054 2057 2031 2000 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] in and it was restricted and i started bring i brought my personal physician down i finally coe ##rce ##d some hospital people to come and got the health department health department to come out and then one one day i decided what we have to do more here and i called up all of the service providers that had anything to do with this and told them to be at the hospital meeting room but i didn ##t tell any of them that they were going to be there i just asked one person to be there and it might have worked with the odd shop shot was as i got all the service providers into one room and sneak away and i looked at them and i said here ##s the problem and you need to fix this and that was the beginning of the yu ##ma county aids project how did they respond negatively at first but it didn ##t take long for some rather learn add people that were there to figure out that know we needed to do something because its by now by that time then some more cases head popped up [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] in and it was restricted and i started bring i brought my personal physician down i finally coe ##rce ##d some hospital people to come and got the health department health department to come out and then one one day i decided what we have to do more here and i called up all of the service providers that had anything to do with this and told them to be at the hospital meeting room but i didn ##t tell any of them that they were going to be there i just asked one person to be there and it might have worked with the odd shop shot was as i got all the service providers into one room and sneak away and i looked at them and i said here ##s the problem and you need to fix this and that was the beginning of the yu ##ma county aids project how did they respond negatively at first but it didn ##t take long for some rather learn add people that were there to figure out that know we needed to do something because its by now by that time then some more cases head popped up [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1999 1998 2009 2001 7775 1998 1045 2318 3288 1045 2716 2026 3167 7522 2091 1045 2633 24873 19170 2094 2070 2902 2111 2000 2272 1998 2288 1996 2740 2533 2740 2533 2000 2272 2041 1998 2059 2028 2028 2154 1045 2787 2054 2057 2031 2000 2079 2062 2182 1998 1045 2170 2039 2035 1997 1996 2326 11670 2008 2018 2505 2000 2079 2007 2023 1998 2409 2068 2000 2022 2012 1996 2902 3116 2282 2021 1045 2134 2102 2425 2151 1997 2068 2008 2027 2020 2183 2000 2022 2045 1045 2074 2356 2028 2711 2000 2022 2045 1998 2009 2453 2031 2499 2007 1996 5976 4497 2915 2001 2004 1045 2288 2035 1996 2326 11670 2046 2028 2282 1998 13583 2185 1998 1045 2246 2012 2068 1998 1045 2056 2182 2015 1996 3291 1998 2017 2342 2000 8081 2023 1998 2008 2001 1996 2927 1997 1996 9805 2863 2221 8387 2622 2129 2106 2027 6869 19762 2012 2034 2021 2009 2134 2102 2202 2146 2005 2070 2738 4553 5587 2111 2008 2020 2045 2000 3275 2041 2008 2113 2057 2734 2000 2079 2242 2138 2049 2011 2085 2011 2008 2051 2059 2070 2062 3572 2132 10538 2039 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1999 1998 2009 2001 7775 1998 1045 2318 3288 1045 2716 2026 3167 7522 2091 1045 2633 24873 19170 2094 2070 2902 2111 2000 2272 1998 2288 1996 2740 2533 2740 2533 2000 2272 2041 1998 2059 2028 2028 2154 1045 2787 2054 2057 2031 2000 2079 2062 2182 1998 1045 2170 2039 2035 1997 1996 2326 11670 2008 2018 2505 2000 2079 2007 2023 1998 2409 2068 2000 2022 2012 1996 2902 3116 2282 2021 1045 2134 2102 2425 2151 1997 2068 2008 2027 2020 2183 2000 2022 2045 1045 2074 2356 2028 2711 2000 2022 2045 1998 2009 2453 2031 2499 2007 1996 5976 4497 2915 2001 2004 1045 2288 2035 1996 2326 11670 2046 2028 2282 1998 13583 2185 1998 1045 2246 2012 2068 1998 1045 2056 2182 2015 1996 3291 1998 2017 2342 2000 8081 2023 1998 2008 2001 1996 2927 1997 1996 9805 2863 2221 8387 2622 2129 2106 2027 6869 19762 2012 2034 2021 2009 2134 2102 2202 2146 2005 2070 2738 4553 5587 2111 2008 2020 2045 2000 3275 2041 2008 2113 2057 2734 2000 2079 2242 2138 2049 2011 2085 2011 2008 2051 2059 2070 2062 3572 2132 10538 2039 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] me no ##mbre zombie sal ##ced ##o unfortunately it stays in marshall than those means yes he is the most grab ##ando en el este de los angeles me no ##mbre sprinter del rio gonzalez tango cu ##are ##nta los an ##os tie ##ne mu ##jer trans ##gen ##ero latin ##a vivian la com ##pani ##a add chip ##ped is the most elevated oh yes it says the marshall at dos mil die ##z la ##gr ##ima ##s del city center del este de los angeles dublin de este gr ##ac ##ias por est ##ar a ##qui mp 2nd western are you going to ta ##co bu ##eno places to camp ok ##eto como es get to your ss ##i get to bio ##s cu ##anto tie ##mp ##o ha ##ce en vent ##a de mar ##zo you can come or dollar em ##pre ##nded ##or american ##o con las gan ##as de ha ##cer days to complete miss me sue ##no see it was made out of this message can you use tooth ##pas ##te missile exam ##en de le ##che rec ##eta to be positive about yourself like to come in to me so i can [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] me no ##mbre zombie sal ##ced ##o unfortunately it stays in marshall than those means yes he is the most grab ##ando en el este de los angeles me no ##mbre sprinter del rio gonzalez tango cu ##are ##nta los an ##os tie ##ne mu ##jer trans ##gen ##ero latin ##a vivian la com ##pani ##a add chip ##ped is the most elevated oh yes it says the marshall at dos mil die ##z la ##gr ##ima ##s del city center del este de los angeles dublin de este gr ##ac ##ias por est ##ar a ##qui mp 2nd western are you going to ta ##co bu ##eno places to camp ok ##eto como es get to your ss ##i get to bio ##s cu ##anto tie ##mp ##o ha ##ce en vent ##a de mar ##zo you can come or dollar em ##pre ##nded ##or american ##o con las gan ##as de ha ##cer days to complete miss me sue ##no see it was made out of this message can you use tooth ##pas ##te missile exam ##en de le ##che rec ##eta to be positive about yourself like to come in to me so i can [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2033 2053 19908 11798 16183 11788 2080 6854 2009 12237 1999 5832 2084 2216 2965 2748 2002 2003 1996 2087 6723 28574 4372 3449 28517 2139 3050 3349 2033 2053 19908 19938 3972 5673 10121 17609 12731 12069 12380 3050 2019 2891 5495 2638 14163 20009 9099 6914 10624 3763 2050 13801 2474 4012 26569 2050 5587 9090 5669 2003 1996 2087 8319 2821 2748 2009 2758 1996 5832 2012 9998 23689 3280 2480 2474 16523 9581 2015 3972 2103 2415 3972 28517 2139 3050 3349 5772 2139 28517 24665 6305 7951 18499 9765 2906 1037 15549 6131 3416 2530 2024 2017 2183 2000 11937 3597 20934 16515 3182 2000 3409 7929 18903 18609 9686 2131 2000 2115 7020 2072 2131 2000 16012 2015 12731 21634 5495 8737 2080 5292 3401 4372 18834 2050 2139 9388 6844 2017 2064 2272 2030 7922 7861 28139 25848 2953 2137 2080 9530 5869 25957 3022 2139 5292 17119 2420 2000 3143 3335 2033 9790 3630 2156 2009 2001 2081 2041 1997 2023 4471 2064 2017 2224 11868 19707 2618 7421 11360 2368 2139 3393 5403 28667 12928 2000 2022 3893 2055 4426 2066 2000 2272 1999 2000 2033 2061 1045 2064 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2033 2053 19908 11798 16183 11788 2080 6854 2009 12237 1999 5832 2084 2216 2965 2748 2002 2003 1996 2087 6723 28574 4372 3449 28517 2139 3050 3349 2033 2053 19908 19938 3972 5673 10121 17609 12731 12069 12380 3050 2019 2891 5495 2638 14163 20009 9099 6914 10624 3763 2050 13801 2474 4012 26569 2050 5587 9090 5669 2003 1996 2087 8319 2821 2748 2009 2758 1996 5832 2012 9998 23689 3280 2480 2474 16523 9581 2015 3972 2103 2415 3972 28517 2139 3050 3349 5772 2139 28517 24665 6305 7951 18499 9765 2906 1037 15549 6131 3416 2530 2024 2017 2183 2000 11937 3597 20934 16515 3182 2000 3409 7929 18903 18609 9686 2131 2000 2115 7020 2072 2131 2000 16012 2015 12731 21634 5495 8737 2080 5292 3401 4372 18834 2050 2139 9388 6844 2017 2064 2272 2030 7922 7861 28139 25848 2953 2137 2080 9530 5869 25957 3022 2139 5292 17119 2420 2000 3143 3335 2033 9790 3630 2156 2009 2001 2081 2041 1997 2023 4471 2064 2017 2224 11868 19707 2618 7421 11360 2368 2139 3393 5403 28667 12928 2000 2022 3893 2055 4426 2066 2000 2272 1999 2000 2033 2061 1045 2064 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] can be left alone in spanish books what im into you and your pro ##no ##un you can tell me where is a stamp in the static electrical me fa ##mi ##lia me some mig ##os proposed parker furniture place that i can make your own credit report email address on my spot ##ify payment thing go and needs to buy stock in california los angeles come over to ex ##per ##ien ##cia cu ##ando to your sister pace arrow o ##culus experiences as a qui ##nce ##ane ##ra as part of my foot on chest pereira ##s led wal ##mart in north end of the comment ##ers at pu ##ert ##a de tr ##aba ##jo de ni ##ro latin ##as in sacramento ca pr ##actic ##ament ##e sam ##y sandra ban ##as port ##acion de co ##cci ##on k kitten yoga to be honest with me ##mento ##s le maria supposed to look into percent alaska ##n of recent immigrants ci ko ##mo ##do services de much ##as gr ##ac ##ias tor ##till ##as is distance email address is 38 mb in a circle symbol argue that mean you coming to you yet cast device to spend [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] can be left alone in spanish books what im into you and your pro ##no ##un you can tell me where is a stamp in the static electrical me fa ##mi ##lia me some mig ##os proposed parker furniture place that i can make your own credit report email address on my spot ##ify payment thing go and needs to buy stock in california los angeles come over to ex ##per ##ien ##cia cu ##ando to your sister pace arrow o ##culus experiences as a qui ##nce ##ane ##ra as part of my foot on chest pereira ##s led wal ##mart in north end of the comment ##ers at pu ##ert ##a de tr ##aba ##jo de ni ##ro latin ##as in sacramento ca pr ##actic ##ament ##e sam ##y sandra ban ##as port ##acion de co ##cci ##on k kitten yoga to be honest with me ##mento ##s le maria supposed to look into percent alaska ##n of recent immigrants ci ko ##mo ##do services de much ##as gr ##ac ##ias tor ##till ##as is distance email address is 38 mb in a circle symbol argue that mean you coming to you yet cast device to spend [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2064 2022 2187 2894 1999 3009 2808 2054 10047 2046 2017 1998 2115 4013 3630 4609 2017 2064 2425 2033 2073 2003 1037 11359 1999 1996 10763 5992 2033 6904 4328 6632 2033 2070 19117 2891 3818 6262 7390 2173 2008 1045 2064 2191 2115 2219 4923 3189 10373 4769 2006 2026 3962 8757 7909 2518 2175 1998 3791 2000 4965 4518 1999 2662 3050 3349 2272 2058 2000 4654 4842 9013 7405 12731 28574 2000 2115 2905 6393 8612 1051 28703 6322 2004 1037 21864 5897 7231 2527 2004 2112 1997 2026 3329 2006 3108 23857 2015 2419 24547 22345 1999 2167 2203 1997 1996 7615 2545 2012 16405 8743 2050 2139 19817 19736 5558 2139 9152 3217 3763 3022 1999 11932 6187 10975 28804 24996 2063 3520 2100 12834 7221 3022 3417 21736 2139 2522 14693 2239 1047 18401 13272 2000 2022 7481 2007 2033 23065 2015 3393 3814 4011 2000 2298 2046 3867 7397 2078 1997 3522 7489 25022 12849 5302 3527 2578 2139 2172 3022 24665 6305 7951 17153 28345 3022 2003 3292 10373 4769 2003 4229 16914 1999 1037 4418 6454 7475 2008 2812 2017 2746 2000 2017 2664 3459 5080 2000 5247 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2064 2022 2187 2894 1999 3009 2808 2054 10047 2046 2017 1998 2115 4013 3630 4609 2017 2064 2425 2033 2073 2003 1037 11359 1999 1996 10763 5992 2033 6904 4328 6632 2033 2070 19117 2891 3818 6262 7390 2173 2008 1045 2064 2191 2115 2219 4923 3189 10373 4769 2006 2026 3962 8757 7909 2518 2175 1998 3791 2000 4965 4518 1999 2662 3050 3349 2272 2058 2000 4654 4842 9013 7405 12731 28574 2000 2115 2905 6393 8612 1051 28703 6322 2004 1037 21864 5897 7231 2527 2004 2112 1997 2026 3329 2006 3108 23857 2015 2419 24547 22345 1999 2167 2203 1997 1996 7615 2545 2012 16405 8743 2050 2139 19817 19736 5558 2139 9152 3217 3763 3022 1999 11932 6187 10975 28804 24996 2063 3520 2100 12834 7221 3022 3417 21736 2139 2522 14693 2239 1047 18401 13272 2000 2022 7481 2007 2033 23065 2015 3393 3814 4011 2000 2298 2046 3867 7397 2078 1997 3522 7489 25022 12849 5302 3527 2578 2139 2172 3022 24665 6305 7951 17153 28345 3022 2003 3292 10373 4769 2003 4229 16914 1999 1037 4418 6454 7475 2008 2812 2017 2746 2000 2017 2664 3459 5080 2000 5247 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] to you yet cast device to spend all 1 sue ##no de me ##jo ##res a este tam ##pic ##o her ##mos ##o er ##es un pri ##nc ##ip ##io you can weigh scales look at other gas estimate can you send me that file a discrimination joseph trans ##cana ##da eco ##ca ##b another mason fort ##ale ##za ##s acid or less than 7 episode ii for mister so that other place was contaminated como est ##as in ##vo ##lu ##cr ##ado direct ##v dallas apprentice percentage me your ##e comfortably market la di ##fer ##encia en mi persona in persona con la mis ##ma por ##que cr ##eo que si you can be able to back up your story instrumental ac ##ropolis campus ke ##owe ##e channel in memphis tennessee department colorado renewal letters grande ##s cakes c state of alaska business universities in ti ##vo ##li laugh out the name associated terminals to give you a local mall simple ##ment ##e hello kitty elvis theater la persona que que ##ma suited and also say that you can simply meant to put european soccer stick ##man houston este ##re ##ot ##ip ##os trans ##cana ##da latin [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] to you yet cast device to spend all 1 sue ##no de me ##jo ##res a este tam ##pic ##o her ##mos ##o er ##es un pri ##nc ##ip ##io you can weigh scales look at other gas estimate can you send me that file a discrimination joseph trans ##cana ##da eco ##ca ##b another mason fort ##ale ##za ##s acid or less than 7 episode ii for mister so that other place was contaminated como est ##as in ##vo ##lu ##cr ##ado direct ##v dallas apprentice percentage me your ##e comfortably market la di ##fer ##encia en mi persona in persona con la mis ##ma por ##que cr ##eo que si you can be able to back up your story instrumental ac ##ropolis campus ke ##owe ##e channel in memphis tennessee department colorado renewal letters grande ##s cakes c state of alaska business universities in ti ##vo ##li laugh out the name associated terminals to give you a local mall simple ##ment ##e hello kitty elvis theater la persona que que ##ma suited and also say that you can simply meant to put european soccer stick ##man houston este ##re ##ot ##ip ##os trans ##cana ##da latin [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2000 2017 2664 3459 5080 2000 5247 2035 1015 9790 3630 2139 2033 5558 6072 1037 28517 17214 24330 2080 2014 15530 2080 9413 2229 4895 26927 12273 11514 3695 2017 2064 17042 9539 2298 2012 2060 3806 10197 2064 2017 4604 2033 2008 5371 1037 9147 3312 9099 28621 2850 17338 3540 2497 2178 6701 3481 9453 4143 2015 5648 2030 2625 2084 1021 2792 2462 2005 12525 2061 2008 2060 2173 2001 19450 18609 9765 3022 1999 6767 7630 26775 9365 3622 2615 5759 13357 7017 2033 2115 2063 18579 3006 2474 4487 7512 27742 4372 2771 16115 1999 16115 9530 2474 28616 2863 18499 4226 13675 8780 10861 9033 2017 2064 2022 2583 2000 2067 2039 2115 2466 6150 9353 23248 3721 17710 29385 2063 3149 1999 9774 5298 2533 5169 14524 4144 9026 2015 22619 1039 2110 1997 7397 2449 5534 1999 14841 6767 3669 4756 2041 1996 2171 3378 17703 2000 2507 2017 1037 2334 6670 3722 3672 2063 7592 14433 12280 4258 2474 16115 10861 10861 2863 10897 1998 2036 2360 2008 2017 2064 3432 3214 2000 2404 2647 4715 6293 2386 5395 28517 2890 4140 11514 2891 9099 28621 2850 3763 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2000 2017 2664 3459 5080 2000 5247 2035 1015 9790 3630 2139 2033 5558 6072 1037 28517 17214 24330 2080 2014 15530 2080 9413 2229 4895 26927 12273 11514 3695 2017 2064 17042 9539 2298 2012 2060 3806 10197 2064 2017 4604 2033 2008 5371 1037 9147 3312 9099 28621 2850 17338 3540 2497 2178 6701 3481 9453 4143 2015 5648 2030 2625 2084 1021 2792 2462 2005 12525 2061 2008 2060 2173 2001 19450 18609 9765 3022 1999 6767 7630 26775 9365 3622 2615 5759 13357 7017 2033 2115 2063 18579 3006 2474 4487 7512 27742 4372 2771 16115 1999 16115 9530 2474 28616 2863 18499 4226 13675 8780 10861 9033 2017 2064 2022 2583 2000 2067 2039 2115 2466 6150 9353 23248 3721 17710 29385 2063 3149 1999 9774 5298 2533 5169 14524 4144 9026 2015 22619 1039 2110 1997 7397 2449 5534 1999 14841 6767 3669 4756 2041 1996 2171 3378 17703 2000 2507 2017 1037 2334 6670 3722 3672 2063 7592 14433 12280 4258 2474 16115 10861 10861 2863 10897 1998 2036 2360 2008 2017 2064 3432 3214 2000 2404 2647 4715 6293 2386 5395 28517 2890 4140 11514 2891 9099 28621 2850 3763 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] trans ##cana ##da latin ##as much has been said when you don ##t start mca ##les ##ter tv stat leaders report them on the speaker ok its been a lot of some experiment in oro ##si ka ##ku ##na com ##pro ##mis ##o de est ##ar a ##qui con ##ti ##go est ##a tr ##aba ##jan ##do por una persona por mis experience every story has a lot of things tobias arizona let me comment a comment on ins ##tagram experience they call maria tam ##bie ##n mean by le ##cr ##ae and a selective ##ly small dam he look look at you all grown up and kingdom internal production flow is the l where are amp ##het ##amine ##s im going home with you and looking for a on jam ##ison center schedule est ##aba i want im waiting for an on ##n me and my car are okay yesterday instrumental espn i mean i get a student loan but im impressed impressed ho ##oni ##gan pay a ticket for look at the material cr ##eo que lo mas important ##e bam ##bi free by lana cc c people are getting a list a to z pin [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] trans ##cana ##da latin ##as much has been said when you don ##t start mca ##les ##ter tv stat leaders report them on the speaker ok its been a lot of some experiment in oro ##si ka ##ku ##na com ##pro ##mis ##o de est ##ar a ##qui con ##ti ##go est ##a tr ##aba ##jan ##do por una persona por mis experience every story has a lot of things tobias arizona let me comment a comment on ins ##tagram experience they call maria tam ##bie ##n mean by le ##cr ##ae and a selective ##ly small dam he look look at you all grown up and kingdom internal production flow is the l where are amp ##het ##amine ##s im going home with you and looking for a on jam ##ison center schedule est ##aba i want im waiting for an on ##n me and my car are okay yesterday instrumental espn i mean i get a student loan but im impressed impressed ho ##oni ##gan pay a ticket for look at the material cr ##eo que lo mas important ##e bam ##bi free by lana cc c people are getting a list a to z pin [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 9099 28621 2850 3763 3022 2172 2038 2042 2056 2043 2017 2123 2102 2707 22432 4244 3334 2694 28093 4177 3189 2068 2006 1996 5882 7929 2049 2042 1037 2843 1997 2070 7551 1999 20298 5332 10556 5283 2532 4012 21572 15630 2080 2139 9765 2906 1037 15549 9530 3775 3995 9765 2050 19817 19736 8405 3527 18499 14477 16115 18499 28616 3325 2296 2466 2038 1037 2843 1997 2477 16858 5334 2292 2033 7615 1037 7615 2006 16021 23091 3325 2027 2655 3814 17214 11283 2078 2812 2011 3393 26775 6679 1998 1037 13228 2135 2235 5477 2002 2298 2298 2012 2017 2035 4961 2039 1998 2983 4722 2537 4834 2003 1996 1048 2073 2024 23713 27065 19915 2015 10047 2183 2188 2007 2017 1998 2559 2005 1037 2006 9389 10929 2415 6134 9765 19736 1045 2215 10047 3403 2005 2019 2006 2078 2033 1998 2026 2482 2024 3100 7483 6150 10978 1045 2812 1045 2131 1037 3076 5414 2021 10047 7622 7622 7570 10698 5289 3477 1037 7281 2005 2298 2012 1996 3430 13675 8780 10861 8840 16137 2590 2063 25307 5638 2489 2011 16554 10507 1039 2111 2024 2893 1037 2862 1037 2000 1062 9231 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 9099 28621 2850 3763 3022 2172 2038 2042 2056 2043 2017 2123 2102 2707 22432 4244 3334 2694 28093 4177 3189 2068 2006 1996 5882 7929 2049 2042 1037 2843 1997 2070 7551 1999 20298 5332 10556 5283 2532 4012 21572 15630 2080 2139 9765 2906 1037 15549 9530 3775 3995 9765 2050 19817 19736 8405 3527 18499 14477 16115 18499 28616 3325 2296 2466 2038 1037 2843 1997 2477 16858 5334 2292 2033 7615 1037 7615 2006 16021 23091 3325 2027 2655 3814 17214 11283 2078 2812 2011 3393 26775 6679 1998 1037 13228 2135 2235 5477 2002 2298 2298 2012 2017 2035 4961 2039 1998 2983 4722 2537 4834 2003 1996 1048 2073 2024 23713 27065 19915 2015 10047 2183 2188 2007 2017 1998 2559 2005 1037 2006 9389 10929 2415 6134 9765 19736 1045 2215 10047 3403 2005 2019 2006 2078 2033 1998 2026 2482 2024 3100 7483 6150 10978 1045 2812 1045 2131 1037 3076 5414 2021 10047 7622 7622 7570 10698 5289 3477 1037 7281 2005 2298 2012 1996 3430 13675 8780 10861 8840 16137 2590 2063 25307 5638 2489 2011 16554 10507 1039 2111 2024 2893 1037 2862 1037 2000 1062 9231 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] cc c people are getting a list a to z pin ##ot compared to get to know i can be a total opposite of un ##ila ##tera ##l mario ##s ta ##cos te ##me ##cula for saturday may 30 minutes to pre end ##o to ##can ##do pu ##ert ##as i see tennessee yo ##nko ##nte lo ##rca nec ##es ##itas es para las tr ##oca ##s de gomez limit on test cricket in coma ##s fort collins escape can you believe that it is your source is a psycho ##sis makes you don ##t compare las co ##sas para para mi com ##uni ##dad you kara ##oke sports cha ##let de pod ##er est ##ar a ##qui cup ##ert ##ino astoria hotel con ##ti ##go por ##que est ##amo ##s odyssey ko ##mo ##l las alma ##s gem ##ela ##s de las call ##es nose for thursday morning stores go to sleep article on how to set up a ticket to nowhere else he could get some compliment today they said his team would listen associate that they said i can visit cam ##bio de musica mas her ##mos ##o de belle ##za turn off kay kay [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] cc c people are getting a list a to z pin ##ot compared to get to know i can be a total opposite of un ##ila ##tera ##l mario ##s ta ##cos te ##me ##cula for saturday may 30 minutes to pre end ##o to ##can ##do pu ##ert ##as i see tennessee yo ##nko ##nte lo ##rca nec ##es ##itas es para las tr ##oca ##s de gomez limit on test cricket in coma ##s fort collins escape can you believe that it is your source is a psycho ##sis makes you don ##t compare las co ##sas para para mi com ##uni ##dad you kara ##oke sports cha ##let de pod ##er est ##ar a ##qui cup ##ert ##ino astoria hotel con ##ti ##go por ##que est ##amo ##s odyssey ko ##mo ##l las alma ##s gem ##ela ##s de las call ##es nose for thursday morning stores go to sleep article on how to set up a ticket to nowhere else he could get some compliment today they said his team would listen associate that they said i can visit cam ##bio de musica mas her ##mos ##o de belle ##za turn off kay kay [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 10507 1039 2111 2024 2893 1037 2862 1037 2000 1062 9231 4140 4102 2000 2131 2000 2113 1045 2064 2022 1037 2561 4500 1997 4895 11733 14621 2140 7986 2015 11937 13186 8915 4168 19879 2005 5095 2089 2382 2781 2000 3653 2203 2080 2000 9336 3527 16405 8743 3022 1045 2156 5298 10930 16107 10111 8840 18992 26785 2229 24317 9686 11498 5869 19817 24755 2015 2139 12791 5787 2006 3231 4533 1999 16571 2015 3481 6868 4019 2064 2017 2903 2008 2009 2003 2115 3120 2003 1037 18224 6190 3084 2017 2123 2102 12826 5869 2522 20939 11498 11498 2771 4012 19496 14697 2017 13173 11045 2998 15775 7485 2139 17491 2121 9765 2906 1037 15549 2452 8743 5740 29285 3309 9530 3775 3995 18499 4226 9765 22591 2015 18735 12849 5302 2140 5869 11346 2015 17070 10581 2015 2139 5869 2655 2229 4451 2005 9432 2851 5324 2175 2000 3637 3720 2006 2129 2000 2275 2039 1037 7281 2000 7880 2842 2002 2071 2131 2070 19394 2651 2027 2056 2010 2136 2052 4952 5482 2008 2027 2056 1045 2064 3942 11503 26282 2139 21137 16137 2014 15530 2080 2139 9852 4143 2735 2125 10905 10905 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 10507 1039 2111 2024 2893 1037 2862 1037 2000 1062 9231 4140 4102 2000 2131 2000 2113 1045 2064 2022 1037 2561 4500 1997 4895 11733 14621 2140 7986 2015 11937 13186 8915 4168 19879 2005 5095 2089 2382 2781 2000 3653 2203 2080 2000 9336 3527 16405 8743 3022 1045 2156 5298 10930 16107 10111 8840 18992 26785 2229 24317 9686 11498 5869 19817 24755 2015 2139 12791 5787 2006 3231 4533 1999 16571 2015 3481 6868 4019 2064 2017 2903 2008 2009 2003 2115 3120 2003 1037 18224 6190 3084 2017 2123 2102 12826 5869 2522 20939 11498 11498 2771 4012 19496 14697 2017 13173 11045 2998 15775 7485 2139 17491 2121 9765 2906 1037 15549 2452 8743 5740 29285 3309 9530 3775 3995 18499 4226 9765 22591 2015 18735 12849 5302 2140 5869 11346 2015 17070 10581 2015 2139 5869 2655 2229 4451 2005 9432 2851 5324 2175 2000 3637 3720 2006 2129 2000 2275 2039 1037 7281 2000 7880 2842 2002 2071 2131 2070 19394 2651 2027 2056 2010 2136 2052 4952 5482 2008 2027 2056 1045 2064 3942 11503 26282 2139 21137 16137 2014 15530 2080 2139 9852 4143 2735 2125 10905 10905 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 3 (id = 3)\n"
     ]
    }
   ],
   "source": [
    "# Convert our train and validation features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \n",
    "  bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "  # Use \"sequence_outputs\" for token-level output.\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "  # with tf.Session() as sess:\n",
    "  output_layer1 = bert_outputs[\"pooled_output\"]\n",
    "  # output_layer1 = 999\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  # Create our own layer to tune for politeness data.\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.8)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs, output_layer1)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        true_pos = tf.metrics.true_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        true_neg = tf.metrics.true_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)   \n",
    "        false_pos = tf.metrics.false_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)  \n",
    "        false_neg = tf.metrics.false_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        \n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            \"true_positives\": true_pos,\n",
    "            \"true_negatives\": true_neg,\n",
    "            \"false_positives\": false_pos,\n",
    "            \"false_negatives\": false_neg,\n",
    "            }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs, output_layer) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels,\n",
    "          'pooled_output': output_layer\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1.0\n",
    "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 300\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "# Compute train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969, 12)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_steps, len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './bert_output/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000021151129F98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './bert_output/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000021151129F98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "#Initializing the model and the estimator\n",
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)\n",
    "\n",
    "# Create an input function for validating. drop_remainder = True for using TPUs.\n",
    "val_input_fn = run_classifier.input_fn_builder(\n",
    "    features=val_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n",
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-42-a75d089b65af>:35: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-42-a75d089b65af>:35: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\bert\\optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.6187994, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.6187994, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.64344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.64344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4642602, step = 100 (37.829 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4642602, step = 100 (37.829 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4032516, step = 200 (27.648 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4032516, step = 200 (27.648 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 300 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 300 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.30003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.30003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4156082, step = 300 (43.478 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4156082, step = 300 (43.478 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.53423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.53423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.181636, step = 400 (28.295 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.181636, step = 400 (28.295 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.5966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.6641572, step = 500 (27.803 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.6641572, step = 500 (27.803 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 600 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 600 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.31246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.31246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.5827614, step = 600 (43.244 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.5827614, step = 600 (43.244 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.63123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.63123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0959247, step = 700 (27.539 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0959247, step = 700 (27.539 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.62109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.62109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.7466471, step = 800 (27.616 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.7466471, step = 800 (27.616 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 900 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 900 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.28086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.28086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.2507892, step = 900 (43.843 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.2507892, step = 900 (43.843 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 969 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 969 into ./bert_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 1.4718494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 1.4718494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took time  0:07:16.634450\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "C:\\Users\\ej\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-09-21T12:00:06Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-09-21T12:00:06Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./bert_output/model.ckpt-969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./bert_output/model.ckpt-969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-09-21-12:00:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-09-21-12:00:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 969: eval_accuracy = 0.62168676, false_negatives = 4.0, false_positives = 261.0, global_step = 969, loss = 1.4183246, true_negatives = 2.0, true_positives = 1808.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 969: eval_accuracy = 0.62168676, false_negatives = 4.0, false_positives = 261.0, global_step = 969, loss = 1.4183246, true_negatives = 2.0, true_positives = 1808.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 969: ./bert_output/model.ckpt-969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 969: ./bert_output/model.ckpt-969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.62168676,\n",
       " 'false_negatives': 4.0,\n",
       " 'false_positives': 261.0,\n",
       " 'loss': 1.4183246,\n",
       " 'true_negatives': 2.0,\n",
       " 'true_positives': 1808.0,\n",
       " 'global_step': 969}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the model with Validation set\n",
    "estimator.evaluate(input_fn=val_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A method to get predictions\n",
    "def getPrediction(in_sentences, type_output = \"features\"):\n",
    "  #A list to map the actual labels to the predictions\n",
    "  labels = np.unique(train['label'])\n",
    "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n",
    "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  #Predicting the classes \n",
    "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "  predictions = estimator.predict(predict_input_fn)\n",
    "  if type_output == \"features\":\n",
    "    return [prediction['pooled_output'] for _,prediction in enumerate(predictions) ]\n",
    "  else:\n",
    "    return ([(sentence, prediction['probabilities'],\n",
    "              prediction['labels'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.logging.ERROR)\n",
    "MAX_SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7756, 2), (2075, 2))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Douglas Sanchez 18 January 16th 2010 Yuma Ariz...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that that particular time contrary to now ther...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bar called The Cameo and at that time traffic ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>was one of the very first projects I ever did ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in and it was restricted and I started bring I...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Douglas Sanchez 18 January 16th 2010 Yuma Ariz...      3\n",
       "1  that that particular time contrary to now ther...      3\n",
       "2  bar called The Cameo and at that time traffic ...      3\n",
       "3  was one of the very first projects I ever did ...      3\n",
       "4  in and it was restricted and I started bring I...      3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transcript_raw = transcript_raw[transcript_raw.human_transcript.notnull()]\n",
    "# train_df = train_df[train_df.DATA_COLUMN.notnull()]\n",
    "# train_df.shape\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tr_emb = np.apply_along_axis(getPrediction, 0,np.array(train_df[DATA_COLUMN]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2075, 768)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "val_emb = np.apply_along_axis(getPrediction, 0,np.array(val_df[DATA_COLUMN]))\n",
    "val_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2075, 768), (7756, 768))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_emb.shape, tr_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = -1\n",
    "len_l = 0\n",
    "train_x = {}\n",
    "for l, emb in zip(index_l, tr_emb):\n",
    "  if l in train_x.keys():\n",
    "    train_x[l]  =np.vstack([train_x[l], emb])\n",
    "  else:\n",
    "    train_x[l] = [emb]\n",
    "\n",
    "len(train_x.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.98831576, -0.44439206, 0.99946404, -0.547...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-0.9883084, -0.44428286, 0.9994648, -0.54771...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.9883366, -0.44480312, 0.9994684, -0.55017...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.9883002, -0.44439593, 0.99946797, -0.5494...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.98991615, -0.44480646, 0.99952805, -0.534...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emb  label\n",
       "0  [[-0.98831576, -0.44439206, 0.99946404, -0.547...      3\n",
       "1  [[-0.9883084, -0.44428286, 0.9994648, -0.54771...      7\n",
       "2  [[-0.9883366, -0.44480312, 0.9994684, -0.55017...      3\n",
       "3  [[-0.9883002, -0.44439593, 0.99946797, -0.5494...      3\n",
       "4  [[-0.98991615, -0.44480646, 0.99952805, -0.534...      3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_l_final = []\n",
    "label_l_final = []\n",
    "for k in train_x.keys():\n",
    "  train_l_final.append(train_x[k])\n",
    "  label_l_final.append(train.loc[k]['label'])\n",
    "\n",
    "df_train = pd.DataFrame({'emb': train_l_final, 'label': label_l_final, })\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.9895326, -0.39228275, 0.9983325, 0.957225...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-0.98831064, -0.44451556, 0.99946845, -0.550...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.9883089, -0.44463697, 0.9994666, -0.54908...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.9883187, -0.44453496, 0.99946785, -0.5491...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.9883031, -0.44428778, 0.9994652, -0.54813...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emb  label\n",
       "0  [[-0.9895326, -0.39228275, 0.9983325, 0.957225...      3\n",
       "1  [[-0.98831064, -0.44451556, 0.99946845, -0.550...      3\n",
       "2  [[-0.9883089, -0.44463697, 0.9994666, -0.54908...      5\n",
       "3  [[-0.9883187, -0.44453496, 0.99946785, -0.5491...      0\n",
       "4  [[-0.9883031, -0.44428778, 0.9994652, -0.54813...      3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = -1\n",
    "len_l = 0\n",
    "val_x = {}\n",
    "\n",
    "for l, emb in zip(val_index_l, val_emb):\n",
    "  if l in val_x.keys():\n",
    "    val_x[l]  =np.vstack([val_x[l], emb])\n",
    "  else:\n",
    "    val_x[l] = [emb]\n",
    "\n",
    "\n",
    "val_l_final = []\n",
    "vlabel_l_final = []\n",
    "for k in val_x.keys():\n",
    "  val_l_final.append(val_x[k])\n",
    "  vlabel_l_final.append(val.loc[k]['label'])\n",
    "\n",
    "df_val = pd.DataFrame({'emb': val_l_final, 'label': vlabel_l_final})\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val, df_test = train_test_split(df_val, test_size=0.4, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text (InputLayer)            (None, None, 768)         0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, None, 768)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               347600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                372       \n",
      "=================================================================\n",
      "Total params: 351,002\n",
      "Trainable params: 351,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "text_input = Input(shape=(None,768,), dtype='float32', name='text')\n",
    "\n",
    "l_mask = layers.Masking(mask_value=-99.)(text_input)\n",
    "# Which we encoded in a single vector via a LSTM\n",
    "encoded_text = layers.LSTM(100,)(l_mask)\n",
    "out_dense = layers.Dense(30, activation='relu')(encoded_text)\n",
    "# And we add a softmax classifier on top\n",
    "out = layers.Dense(len(label_list), activation='softmax')(out_dense)\n",
    "# At model instantiation, we specify the input and the output:\n",
    "model = Model(text_input, out)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((265, 2), (40, 2), (27, 2))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sequences = len(df_train['emb'].to_list())\n",
    "num_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences = len(df_train['emb'].to_list())\n",
    "batch_size = 5\n",
    "batches_per_epoch =  53\n",
    "assert batch_size * batches_per_epoch == num_sequences\n",
    "num_features= 768\n",
    "def train_generator(df):\n",
    "    x_list= df['emb'].to_list()\n",
    "    y_list =  df.label.to_list()\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch):\n",
    "            longest_index = (b + 1) * batch_size - 1\n",
    "            timesteps = len(max(df['emb'].to_list()[:(b + 1) * batch_size][-batch_size:], key=len))\n",
    "            x_train = np.full((batch_size, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size,  1))\n",
    "            for i in range(batch_size):\n",
    "                li = b * batch_size + i\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sequences_val = len(df_val['emb'].to_list())\n",
    "num_sequences_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences_val = len(df_val['emb'].to_list())\n",
    "batch_size_val = 4\n",
    "batches_per_epoch_val = 10\n",
    "assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
    "num_features= 768\n",
    "def val_generator(df):\n",
    "    x_list= df['emb'].to_list()\n",
    "    y_list =  df.label.to_list()\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch_val):\n",
    "            longest_index = (b + 1) * batch_size_val - 1\n",
    "            timesteps = len(max(df['emb'].to_list()[:(b + 1) * batch_size_val][-31:], key=len))\n",
    "            # print(len(df_train['emb'].to_list()[:b+batch_size][-7:]))\n",
    "            x_train = np.full((batch_size_val, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size_val,  1))\n",
    "            for i in range(batch_size_val):\n",
    "                li = b * batch_size_val + i\n",
    "                # print(\"li\", li)\n",
    "                # print(x_train[i, 0:len(x_list[li]), :].shape, len(x_list[li]))\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "call_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.95, patience=3, verbose=2,\n",
    "                                mode='auto', min_delta=0.01, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 1.8110 - acc: 0.4415 - val_loss: 1.7709 - val_acc: 0.5500\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.6255 - acc: 0.4679 - val_loss: 1.6116 - val_acc: 0.5500\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.5994 - acc: 0.4679 - val_loss: 1.5563 - val_acc: 0.5500\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 1.5911 - acc: 0.4679 - val_loss: 1.5271 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.5864 - acc: 0.4679 - val_loss: 1.5158 - val_acc: 0.5500\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.5850 - acc: 0.4679 - val_loss: 1.5103 - val_acc: 0.5500\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.5836 - acc: 0.4679 - val_loss: 1.5083 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.5814 - acc: 0.4679 - val_loss: 1.5071 - val_acc: 0.5500\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.5852 - acc: 0.4679 - val_loss: 1.5105 - val_acc: 0.5500\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.5809 - acc: 0.4679 - val_loss: 1.5086 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x212e24fac18>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator(df_train), steps_per_epoch=batches_per_epoch, epochs=10,\n",
    "                    validation_data=val_generator(df_val), validation_steps=batches_per_epoch_val, callbacks =[call_reduce] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sequences_val = len(df_test['emb'].to_list())\n",
    "num_sequences_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5186076164245605, 0.5925925970077515]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sequences_val = len(df_test['emb'].to_list())\n",
    "batch_size_val = 9\n",
    "batches_per_epoch_val = 3\n",
    "assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
    "num_features= 768\n",
    "model.evaluate_generator(val_generator(df_test), steps= batches_per_epoch_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
